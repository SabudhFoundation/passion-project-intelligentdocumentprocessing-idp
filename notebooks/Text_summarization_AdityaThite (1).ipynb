{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "19d0f7d28e4e4a55b191b57dff4a4625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56daf530d0bc49a0966650e181c1d214",
              "IPY_MODEL_e9feab844dec4db79b945bd4571d5943",
              "IPY_MODEL_c3f0ebc95d5f407c994411e86fa12a07"
            ],
            "layout": "IPY_MODEL_9a623bbca4bb4de2a18bce819a5baaee"
          }
        },
        "56daf530d0bc49a0966650e181c1d214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f000ef13c5c34271b33e4d43120632b6",
            "placeholder": "​",
            "style": "IPY_MODEL_5d7641c4c7904f569139be4a979c6fec",
            "value": "config.json: 100%"
          }
        },
        "e9feab844dec4db79b945bd4571d5943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98255133bd094d07827f6a53792fb444",
            "max": 1209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b6fe92727604292aa04faaec26e30cf",
            "value": 1209
          }
        },
        "c3f0ebc95d5f407c994411e86fa12a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f418463d30c74f0b8de6d8df9f2c57b8",
            "placeholder": "​",
            "style": "IPY_MODEL_44ec5728633a46d0a8134b65c25f2594",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 52.2kB/s]"
          }
        },
        "9a623bbca4bb4de2a18bce819a5baaee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f000ef13c5c34271b33e4d43120632b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d7641c4c7904f569139be4a979c6fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98255133bd094d07827f6a53792fb444": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b6fe92727604292aa04faaec26e30cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f418463d30c74f0b8de6d8df9f2c57b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44ec5728633a46d0a8134b65c25f2594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39a815ac44af4ff9b2b304908e562a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd37a6d7bef5463c80f479fcec8e75c5",
              "IPY_MODEL_287b5863ff5e4e81b0acc1bef42e2410",
              "IPY_MODEL_d39a6977de0a458b8d774ca4af0a65a2"
            ],
            "layout": "IPY_MODEL_53d6acf752694ea29d6891a8bf3fa0ac"
          }
        },
        "bd37a6d7bef5463c80f479fcec8e75c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a4dd0a3febb4d468e73693134863399",
            "placeholder": "​",
            "style": "IPY_MODEL_db1e7a2fd250429790a7eb90102027c6",
            "value": "model.safetensors: 100%"
          }
        },
        "287b5863ff5e4e81b0acc1bef42e2410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0af52a5409414381aead233bd6824181",
            "max": 2950736730,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfe4728c2a074c5e9f007109214d17cd",
            "value": 2950736730
          }
        },
        "d39a6977de0a458b8d774ca4af0a65a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a015db37b544cb6a681fbced31acbf5",
            "placeholder": "​",
            "style": "IPY_MODEL_ef5bd460953b474e8b7139442a3a4c24",
            "value": " 2.95G/2.95G [01:15&lt;00:00, 38.2MB/s]"
          }
        },
        "53d6acf752694ea29d6891a8bf3fa0ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a4dd0a3febb4d468e73693134863399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db1e7a2fd250429790a7eb90102027c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0af52a5409414381aead233bd6824181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfe4728c2a074c5e9f007109214d17cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a015db37b544cb6a681fbced31acbf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef5bd460953b474e8b7139442a3a4c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7cad6220b3049e69279289e8c3237a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd65e14f7fe745c4bc52cef73a08beff",
              "IPY_MODEL_46608fa9210b4ad2aab97a4a94b82587",
              "IPY_MODEL_1ec4ebd3bb5541aaa56002e14c8ee789"
            ],
            "layout": "IPY_MODEL_92041a7500294be98f39200981e4a8b5"
          }
        },
        "fd65e14f7fe745c4bc52cef73a08beff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73081968c5ba4bcca1ac38cc6ed2d039",
            "placeholder": "​",
            "style": "IPY_MODEL_f13d3be6be6d4f07ad79881e0bbad463",
            "value": "generation_config.json: 100%"
          }
        },
        "46608fa9210b4ad2aab97a4a94b82587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbe3242920eb43d49a937b14cd200c9d",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2999499e91f34b8e89e6869eb69d1cd1",
            "value": 147
          }
        },
        "1ec4ebd3bb5541aaa56002e14c8ee789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc09c91ecba44ccd87f4c1b32445eb6f",
            "placeholder": "​",
            "style": "IPY_MODEL_a7c6d763de7f472c806ea1b7e630f657",
            "value": " 147/147 [00:00&lt;00:00, 3.49kB/s]"
          }
        },
        "92041a7500294be98f39200981e4a8b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73081968c5ba4bcca1ac38cc6ed2d039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f13d3be6be6d4f07ad79881e0bbad463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbe3242920eb43d49a937b14cd200c9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2999499e91f34b8e89e6869eb69d1cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc09c91ecba44ccd87f4c1b32445eb6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7c6d763de7f472c806ea1b7e630f657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e332862963541ef9587bb4b99e380ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b64f20f7795b410fa501616df1f22f27",
              "IPY_MODEL_4feb99d067d140699543dbadb995b61b",
              "IPY_MODEL_7a5e7dbd5c7c40b89faf899d03ed946e"
            ],
            "layout": "IPY_MODEL_af4ae633770a4e54af02410da8b79e79"
          }
        },
        "b64f20f7795b410fa501616df1f22f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f9298505b264bdab5559fb835fe3d32",
            "placeholder": "​",
            "style": "IPY_MODEL_4608b0a507c143dd8a5e8f0961942572",
            "value": "spiece.model: 100%"
          }
        },
        "4feb99d067d140699543dbadb995b61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e79d20540fd840d5a1117b00bc0bf141",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db693bcaaf324bf4916949d27076eaab",
            "value": 791656
          }
        },
        "7a5e7dbd5c7c40b89faf899d03ed946e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dd8e1d0396945839372a9f3728a623c",
            "placeholder": "​",
            "style": "IPY_MODEL_5138bfb181f04190854f6e6acc048f11",
            "value": " 792k/792k [00:00&lt;00:00, 2.33MB/s]"
          }
        },
        "af4ae633770a4e54af02410da8b79e79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9298505b264bdab5559fb835fe3d32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4608b0a507c143dd8a5e8f0961942572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e79d20540fd840d5a1117b00bc0bf141": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db693bcaaf324bf4916949d27076eaab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5dd8e1d0396945839372a9f3728a623c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5138bfb181f04190854f6e6acc048f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "861c77b2c3d04ba1a6bf5934beb98af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa759ba1b78249b2b7c69ab82c18d77e",
              "IPY_MODEL_5b00c9e7ca2f4123bb76019959212e0d",
              "IPY_MODEL_d2e01f18b38649e299db4bf1eb4bf56b"
            ],
            "layout": "IPY_MODEL_5fd86e83b2eb42a7ace5499722ca2177"
          }
        },
        "fa759ba1b78249b2b7c69ab82c18d77e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7b58a8b44ff4907bedb11eb4b5fa94f",
            "placeholder": "​",
            "style": "IPY_MODEL_74bd6ee206174ad78b534ea035f9f00b",
            "value": "tokenizer.json: 100%"
          }
        },
        "5b00c9e7ca2f4123bb76019959212e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e890d5c39451421588cf6e6a97d731bb",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee5d81e9ec184153b95e0fd18c36110e",
            "value": 1389353
          }
        },
        "d2e01f18b38649e299db4bf1eb4bf56b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae16096c3b514034aec18a4363dc62d2",
            "placeholder": "​",
            "style": "IPY_MODEL_fd64ad29cc1a4d85b1d1817ae78294ca",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 3.91MB/s]"
          }
        },
        "5fd86e83b2eb42a7ace5499722ca2177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7b58a8b44ff4907bedb11eb4b5fa94f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74bd6ee206174ad78b534ea035f9f00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e890d5c39451421588cf6e6a97d731bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee5d81e9ec184153b95e0fd18c36110e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae16096c3b514034aec18a4363dc62d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd64ad29cc1a4d85b1d1817ae78294ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#T5\n",
        "\n",
        "T5 (Text-To-Text Transfer Transformer) is a state-of-the-art language model developed by Google, capable of performing various natural language processing tasks, including text summarization. Here are some pros and cons of using T5 for text summarization:\n",
        "\n",
        "Pros:\n",
        "\n",
        "High accuracy: T5 has achieved state-of-the-art results in various natural language processing tasks, including text summarization, making it highly accurate and reliable.\n",
        "Customizable: T5 allows customization of the text summarization model based on specific requirements and domains, making it highly adaptable to various use cases.\n",
        "Multilingual: T5 can be trained on various languages, making it a valuable tool for summarizing text in multiple languages.\n",
        "Abstractive summarization: T5 can perform abstractive summarization, which means it can generate summaries by synthesizing new sentences that are not present in the original text, providing more context and nuance.\n",
        "Cons:\n",
        "\n",
        "Resource-intensive: Training T5 for text summarization requires a considerable amount of computational resources, making it difficult to train and deploy for small-scale projects.\n",
        "Technical complexity: T5 is a complex model that requires advanced technical knowledge to set up, train, and deploy, making it less accessible to non-experts.\n",
        "Limited interpretability: As with other deep learning models, T5's inner workings can be difficult to interpret, making it challenging to understand why the model produces specific summaries.\n",
        "Limited scalability: T5's computational requirements and complexity make it challenging to scale up for large-scale text summarization projects.\n",
        "These are the scores we achieved:\n",
        "\n",
        "  ROUGE Score:\n",
        "  Precision: 0.913\n",
        "  Recall: 0.417\n",
        "  F1-Score: 0.573\n",
        "\n",
        "  BLEU Score: 0.683\n",
        "References\n",
        "Here are some research papers on text summarization using T5:\n",
        "\n",
        "\"Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping\" by Yinhan Liu, et al. This paper presents a method for fine-tuning T5 for text summarization, achieving state-of-the-art results on the CNN/Daily Mail dataset.\n",
        "\n",
        "\"Controllable Abstractive Summarization\" by Peng Xu, et al. This paper proposes a method for controlling the level of abstraction in T5-generated summaries, improving the quality and fluency of the summaries.\n",
        "\n",
        "\"Scalable Neural Methods for Reasoning with a Symbolic Knowledge Graph\" by Kelvin Guu, et al. This paper presents a method for summarizing knowledge graphs using T5, achieving state-of-the-art results on multiple datasets.\n",
        "\n",
        "\"Pretraining-Based Natural Language Generation for Text Summarization\" by Zhe Gan, et al. This paper proposes a method for pretraining T5 for text summarization, improving the quality and diversity of generated summaries.\n",
        "\n",
        "These are just a few examples of research papers on text summarization using T5. There are many more papers and ongoing research in this field."
      ],
      "metadata": {
        "id": "BmWBFWcB3QYf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8bykYY0wRNB",
        "outputId": "762751a2-544b-4c29-da73-de51be282388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers\n",
        "!pip install sentencepiece\n",
        "!pip install rouge\n",
        "!pip install nltk\n",
        "import torch\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import json\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
        "from rouge import Rouge\n",
        "import torch\n",
        "import json\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained('t5-large')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-large')\n",
        "device = torch.device('cpu')\n",
        "\n",
        "text =\"\"\"\n",
        " India's Health Ministry has announced that the country's COVID-19 vaccination drive will now be expanded to include people over the age of 60 and those over 45 with co-morbidities. The move is expected to cover an additional 270 million people, making it one of the largest vaccination drives in the world.The decision was taken after a meeting of the National Expert Group on Vaccine Administration for COVID-19 (NEGVAC), which recommended the expansion of the vaccination program. The NEGVAC also suggested that private hospitals may be allowed to administer the vaccine, although the details of this are yet to be finalized.India began its vaccination drive in mid-January, starting with healthcare and frontline workers. Since then, over 13 million doses have been administered across the country. However, the pace of the vaccination drive has been slower than expected, with concerns raised over vaccine hesitancy and logistical challenges.The expansion of the vaccination drive to include the elderly and those with co-morbidities is a major step towards achieving herd immunity and controlling the spread of the virus in India. The Health Ministry has also urged eligible individuals to come forward and get vaccinated at the earliest.India has reported over 11 million cases of COVID-19, making it the second-worst affected country in the world after the United States. The country's daily case count has been declining in recent weeks, but experts have warned that the pandemic is far from over and that precautions need to be maintained.\n",
        "In summary, India's Health Ministry has announced that the country's COVID-19 vaccination drive will be expanded to include people over 60 and those over 45 with co-morbidities, covering an additional 270 million people. The decision was taken after a meeting of the National Expert Group on Vaccine Administration for COVID-19, and is a major step towards achieving herd immunity and controlling the spread of the virus in India.\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336,
          "referenced_widgets": [
            "19d0f7d28e4e4a55b191b57dff4a4625",
            "56daf530d0bc49a0966650e181c1d214",
            "e9feab844dec4db79b945bd4571d5943",
            "c3f0ebc95d5f407c994411e86fa12a07",
            "9a623bbca4bb4de2a18bce819a5baaee",
            "f000ef13c5c34271b33e4d43120632b6",
            "5d7641c4c7904f569139be4a979c6fec",
            "98255133bd094d07827f6a53792fb444",
            "9b6fe92727604292aa04faaec26e30cf",
            "f418463d30c74f0b8de6d8df9f2c57b8",
            "44ec5728633a46d0a8134b65c25f2594",
            "39a815ac44af4ff9b2b304908e562a65",
            "bd37a6d7bef5463c80f479fcec8e75c5",
            "287b5863ff5e4e81b0acc1bef42e2410",
            "d39a6977de0a458b8d774ca4af0a65a2",
            "53d6acf752694ea29d6891a8bf3fa0ac",
            "4a4dd0a3febb4d468e73693134863399",
            "db1e7a2fd250429790a7eb90102027c6",
            "0af52a5409414381aead233bd6824181",
            "dfe4728c2a074c5e9f007109214d17cd",
            "8a015db37b544cb6a681fbced31acbf5",
            "ef5bd460953b474e8b7139442a3a4c24",
            "b7cad6220b3049e69279289e8c3237a8",
            "fd65e14f7fe745c4bc52cef73a08beff",
            "46608fa9210b4ad2aab97a4a94b82587",
            "1ec4ebd3bb5541aaa56002e14c8ee789",
            "92041a7500294be98f39200981e4a8b5",
            "73081968c5ba4bcca1ac38cc6ed2d039",
            "f13d3be6be6d4f07ad79881e0bbad463",
            "cbe3242920eb43d49a937b14cd200c9d",
            "2999499e91f34b8e89e6869eb69d1cd1",
            "dc09c91ecba44ccd87f4c1b32445eb6f",
            "a7c6d763de7f472c806ea1b7e630f657",
            "2e332862963541ef9587bb4b99e380ec",
            "b64f20f7795b410fa501616df1f22f27",
            "4feb99d067d140699543dbadb995b61b",
            "7a5e7dbd5c7c40b89faf899d03ed946e",
            "af4ae633770a4e54af02410da8b79e79",
            "1f9298505b264bdab5559fb835fe3d32",
            "4608b0a507c143dd8a5e8f0961942572",
            "e79d20540fd840d5a1117b00bc0bf141",
            "db693bcaaf324bf4916949d27076eaab",
            "5dd8e1d0396945839372a9f3728a623c",
            "5138bfb181f04190854f6e6acc048f11",
            "861c77b2c3d04ba1a6bf5934beb98af8",
            "fa759ba1b78249b2b7c69ab82c18d77e",
            "5b00c9e7ca2f4123bb76019959212e0d",
            "d2e01f18b38649e299db4bf1eb4bf56b",
            "5fd86e83b2eb42a7ace5499722ca2177",
            "d7b58a8b44ff4907bedb11eb4b5fa94f",
            "74bd6ee206174ad78b534ea035f9f00b",
            "e890d5c39451421588cf6e6a97d731bb",
            "ee5d81e9ec184153b95e0fd18c36110e",
            "ae16096c3b514034aec18a4363dc62d2",
            "fd64ad29cc1a4d85b1d1817ae78294ca"
          ]
        },
        "id": "WqjV9R3qyIY7",
        "outputId": "2b3dbac4-011b-4c70-ef1d-14864f151e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19d0f7d28e4e4a55b191b57dff4a4625"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39a815ac44af4ff9b2b304908e562a65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7cad6220b3049e69279289e8c3237a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e332862963541ef9587bb4b99e380ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "861c77b2c3d04ba1a6bf5934beb98af8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
        "t5_prepared_Text = \"summarize: \"+preprocess_text\n",
        "print (\"original text preprocessed: \\n\", preprocess_text)\n",
        "\n",
        "tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LY9zFWvyeLJ",
        "outputId": "ac6d6399-31b4-42a7-d05a-006961e9de33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original text preprocessed: \n",
            " India's Health Ministry has announced that the country's COVID-19 vaccination drive will now be expanded to include people over the age of 60 and those over 45 with co-morbidities. The move is expected to cover an additional 270 million people, making it one of the largest vaccination drives in the world.The decision was taken after a meeting of the National Expert Group on Vaccine Administration for COVID-19 (NEGVAC), which recommended the expansion of the vaccination program. The NEGVAC also suggested that private hospitals may be allowed to administer the vaccine, although the details of this are yet to be finalized.India began its vaccination drive in mid-January, starting with healthcare and frontline workers. Since then, over 13 million doses have been administered across the country. However, the pace of the vaccination drive has been slower than expected, with concerns raised over vaccine hesitancy and logistical challenges.The expansion of the vaccination drive to include the elderly and those with co-morbidities is a major step towards achieving herd immunity and controlling the spread of the virus in India. The Health Ministry has also urged eligible individuals to come forward and get vaccinated at the earliest.India has reported over 11 million cases of COVID-19, making it the second-worst affected country in the world after the United States. The country's daily case count has been declining in recent weeks, but experts have warned that the pandemic is far from over and that precautions need to be maintained.In summary, India's Health Ministry has announced that the country's COVID-19 vaccination drive will be expanded to include people over 60 and those over 45 with co-morbidities, covering an additional 270 million people. The decision was taken after a meeting of the National Expert Group on Vaccine Administration for COVID-19, and is a major step towards achieving herd immunity and controlling the spread of the virus in India.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "summary_ids = model.generate(tokenized_text,\n",
        "                                    num_beams=4,\n",
        "                                    no_repeat_ngram_size=2,\n",
        "                                    min_length=30,\n",
        "                                    max_length=700)\n",
        "\n",
        "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print (\"\\n\\nSummarized text: \\n\",output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yULfzLX_yn90",
        "outputId": "09ca28c6-5eec-41ca-e16e-33e71bb7e689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Summarized text: \n",
            " the move is expected to cover an additional 270 million people. it is a major step towards achieving herd immunity and controlling the spread of the virus in india. india has reported over 11 million cases of COVID-19, making it the second-worst affected country in the world after the united states.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(output, text)\n",
        "print(\"ROUGE Score:\")\n",
        "print(\"Precision: {:.3f}\".format(scores[0]['rouge-1']['p']))\n",
        "print(\"Recall: {:.3f}\".format(scores[0]['rouge-1']['r']))\n",
        "print(\"F1-Score: {:.3f}\".format(scores[0]['rouge-1']['f']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl6FD4jA3ehQ",
        "outputId": "de047323-3b02-41e0-ae87-b77dfeac4df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Score:\n",
            "Precision: 0.925\n",
            "Recall: 0.245\n",
            "F1-Score: 0.387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def summary_to_sentences(summary):\n",
        "    # Split the summary into sentences using the '.' character as a separator\n",
        "    sentences = summary.split('.')\n",
        "\n",
        "    # Convert each sentence into a list of words\n",
        "    sentence_lists = [sentence.split() for sentence in sentences]\n",
        "\n",
        "    return sentence_lists\n",
        "\n",
        "def paragraph_to_wordlist(paragraph):\n",
        "    # Split the paragraph into words using whitespace as a separator\n",
        "    words = paragraph.split()\n",
        "    return words\n",
        "\n",
        "reference_paragraph = text\n",
        "reference_summary = summary_to_sentences(reference_paragraph)\n",
        "predicted_paragraph = output\n",
        "predicted_summary = paragraph_to_wordlist(predicted_paragraph)\n",
        "\n",
        "score = sentence_bleu(reference_summary, predicted_summary)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WGjlU2m30H-",
        "outputId": "79b93940-7806-4173-c119-e6d139597d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7765680128156733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BLEU Score T5-large: {:.3f}\".format(score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWGTI53z341j",
        "outputId": "c2ccad4c-aa6e-4d51-c8ff-2bf8efa3b9c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score T5-large: 0.777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b-zTnCb38uD",
        "outputId": "be84bd60-9400-4671-e889-5c8249d3cbf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.31.5-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.16.4 (from gradio)\n",
            "  Downloading gradio_client-0.16.4-py3-none-any.whl (315 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.9/315.9 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.0)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.4->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.4->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=1535be26ecf247e031112e09c64d29233cd4357972a51ffaf778225b4fb4ee18\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, typer, httpx, gradio-client, fastapi-cli, fastapi, gradio\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.31.5 gradio-client-0.16.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.3 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.4 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 typer-0.12.3 ujson-5.10.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def summarizeText(text):\n",
        "    preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
        "    tokenized_text = tokenizer.encode(\"summarize: \"+preprocess_text, return_tensors=\"pt\").to(device)\n",
        "    summary_ids = model.generate(tokenized_text, num_beams=4, no_repeat_ngram_size=2, min_length = 50, max_length=700)\n",
        "\n",
        "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return output\n",
        "\n",
        "demo = gr.Interface(fn = summarizeText, inputs=[\"text\"], outputs=[\"text\"])\n",
        "\n",
        "demo.launch(share = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "EqeZv_zC4DJk",
        "outputId": "6b78d989-c386-419e-8e79-eb32fda7fcdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://ee1404bc5eaf25b409.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ee1404bc5eaf25b409.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF\n",
        "**TF-IDF (Term Frequency-Inverse Document Frequency)** is a common technique used for information retrieval and text summarization. Here are some advantages and disadvantages of using TF-IDF for text summarization:\n",
        "\n",
        "### Pros:\n",
        "\n",
        "* TF-IDF is a simple and computationally efficient method for ranking and summarizing documents based on the importance of their terms.\n",
        "* TF-IDF takes into account the frequency of a term in a document and across the entire corpus, which can help identify important and unique words for summarization.\n",
        "* TF-IDF can be customized to weigh certain terms more heavily based on their relevance to the topic, allowing for more targeted and accurate summaries.\n",
        "* TF-IDF can be easily implemented and requires minimal preprocessing, making it a practical choice for small datasets or simpler NLP tasks.\n",
        "\n",
        "### Disadvantages:\n",
        "\n",
        "* TF-IDF only considers the importance of individual terms, without taking into account the relationships between them or the context in which they appear.\n",
        "* TF-IDF can be sensitive to the length of documents, as longer documents may contain more unique terms and be ranked higher in importance, regardless of their actual relevance to the topic.\n",
        "* TF-IDF does not capture the semantic meaning of terms, which can lead to inaccurate summaries that miss important concepts or nuances.\n",
        "* TF-IDF assumes that all terms are equally important within a document, which may not be the case in certain contexts where certain terms carry more weight or have greater impact on the overall meaning.\n",
        "\n",
        "Overall, TF-IDF can be a useful technique for text summarization in certain contexts, but it has limitations and may not be suitable for all use cases. Its advantages and disadvantages should be carefully considered when selecting a summarization method.\n",
        "\n",
        "These are the scores we achieved:\n",
        "\n",
        "    ROUGE Score:\n",
        "    Precision: 0.787\n",
        "    Recall: 0.266\n",
        "    F1-Score: 0.398\n",
        "\n",
        "    BLEU Score: 0.008\n",
        "\n",
        "Here are some research papers related to using TF-IDF for text summarization:\n",
        "\n",
        "1. \"Automatic text summarization using TF-IDF weighting scheme\" by R. Wan, D. Zhao, and C. Xu, in Proceedings of the 2010 IEEE International Conference on Intelligent Computing and Intelligent Systems (ICIS)\n",
        "\n",
        "2. \"A comparison study of TF-IDF, LSA and multi-words for text classification\" by T. Nasukawa and J. Yi, in Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (HLT-NAACL)\n",
        "\n",
        "3. \"Extractive summarization using continuous vector space models\" by R. Nallapati, B. Zhou, and C. Gulcehre, in Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)\n",
        "\n",
        "4. \"Text summarization with TF-IDF weighted word embedding\" by J. Nam and E. Han, in Proceedings of the 2017 IEEE International Conference on Big Data and Smart Computing (BigComp)\n",
        "\n",
        "These papers explore different aspects of using TF-IDF for text summarization, such as its effectiveness in producing high-quality summaries, its comparison with other techniques like latent semantic analysis, and its combination with other techniques like continuous vector space models and word embeddings.\n",
        "\n",
        "The papers suggest that TF-IDF is a simple and effective approach to summarization, particularly for extractive summarization, where sentences are selected from the original document. The use of TF-IDF can help identify the most important words in the document and select the sentences that contain them, leading to a more informative summary.\n"
      ],
      "metadata": {
        "id": "-c-wLE8Z8Y-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "import pandas\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpNQyRar8aJQ",
        "outputId": "c46ffaef-115a-493c-be5a-f51a1d976542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "!pip install rouge\n",
        "!pip install nltk\n",
        "from rouge import Rouge\n",
        "import nltk\n",
        "import nltk.translate.bleu_score as bleu\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGt-vdxw8iwW",
        "outputId": "0c03b542-0960-4b15-d27f-96af7d9f9d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"\"\"10 Reads for Data Scientists Getting Started with Business Models If youâ€™re getting started with data science, youâ€™re probably focusing your attention on mostly stats and coding. Thereâ€™s nothing wrong with this, in fact, this is the right move â€” these are essential skills that you need to develop early on in your journey. With this being said, the biggest knowledge gap that Iâ€™ve encountered during my data science journey doesnâ€™t deal with either of these areas. Instead, upon starting my first full-time role as a data scientist, I realized, to my surprise, that I didnâ€™t really understand business. I suspect that this is a common theme. If you studied a technical field in college or picked things up using online courses, itâ€™s unlikely that you ever had any reason to deep dive into business concepts like models, strategy, or important metrics. Adding on to this, I didnâ€™t really come across data science interviews that stress-tested this type of understanding. Plenty of them tried to get a sense of product intuition, but I found that it rarely went beyond that. The fact is that business understanding isnâ€™t taught or evangelized in the data science community to the extent that itâ€™s used in practice. The goal of this post is to help bridge this gap by sharing some of the resources that I found most helpful as I got up to speed on how businesses work from the inside-out. This article from Andreessen Horowitz is a great place to start if youâ€™re trying to get familiar with the slew of metrics and acronyms that get thrown around in a business, whether itâ€™s a startup or not. On a more general note, their posts are consistently high-quality and are almost always worth your time. If you have a larger appetite, check out their follow-up post on 16 more metrics and the thread below for some additional tips on metrics. Some helpful tips on misleading metrics An overall solid resource, the articles at FourWeekMBA are worth exploring at some point. I particularly recommend this for an overview of all the different business models out there. Itâ€™s hard to come away from this without learning something new. For a more practical dive into business models, I also found this post going over how Slack makes money interesting. This one is a bit denser than the previous two, but itâ€™s really excellent. The unmissable Ben Thompson from Stratechery goes over how markets work and why certain companies are dominating their industry. The takeaway from this post is that markets have three components, and the companies that can monopolize two of the three typically win out in a big way. Think Netflix. A lot of what weâ€™ve seen so far has been conceptual, so letâ€™s look at a specific model and analyze why it does and doesnâ€™t work. Another one of my favorite business writers out there, Andrew Chen looks at the dating industry and why most investors donâ€™t find it attractive. Other great essays from the venture capitalist commonly cover things like growth and metrics. More from Ben Thompson, hereâ€™s another great essay from him. This time on how large companies, particularly Facebook and Google, process data from its raw form to something uniquely valuable. Published in Fall 2018, this provides a good early look into the business side of all of the data privacy and regulation concerns weâ€™re seeing now. If youâ€™re not familiar with LTV (lifetime value), then youâ€™ll probably have to get familiar with it at some point. Thereâ€™s plenty of resources out there regarding the metric, but this is probably my favorite go-to on the subject. It clearly explains how to calculate LTV, and why you should think twice before you blindly buy into it without context. This short post focuses on the SaaS (software as a service) business model. The basic idea is outlined quite simply in the picture below, but Iâ€™d still recommend you take the time to read the full write-up. Christoph Janz really does an excellent job of taking a complex question and breaking it down. He also recently updated the chart in a new post. Co-founder and former CEO of StackOverflow, Joel Spolsky hammers home a crucial part-business, part-economics lesson here: Smart companies try to commoditize their productsâ€™ complements. Whether they succeed or not is a very different story, shown here with plenty of examples. We covered a few ways that companies can make money, but this resource takes the most simplistic (and still accurate) approach. It all started with Jim Barksdale at a trade show. As he was heading out the door to catch a flight, he left the audience with one last pearl of wisdom before departing, one that sums up the post quite nicely. â€œGentlemen, thereâ€™s only two ways I know of to make money: bundling and unbundling.â€ Last but not least, if you want to take things a step further, I recommend case studies. You can find a ton of them out there from top universities like Stanford and Harvard for cheap or often no cost at all. Once you have a grasp on the fundamentals, this an excellent way to continue to supplement your learning. This is where Iâ€™m currently at â€” Iâ€™ve challenged myself to take on one case study every two weeks over the summer. Join me on the ride! Wrapping Up That does it for the list. I know all of the above links really helped me out and I hope you take the time to explore them. As you might have noticed, not all of them tie into the day-to-day life of a data scientist â€” thatâ€™s intentional. I said this in my last post, Iâ€™ll say it again â€” data scientists are thinkers. We do our best work when we understand the systems that surround us. This understanding is what sets us up for the cool stuff: exploratory analysis, machine learning, and data visualization. Lay the foundation first and reap the benefits later. Thatâ€™s what itâ€™s all about. The resources selected above were heavily influenced by SVP of Strategy at Squarespace, Andrew Bartholomewâ€™s reading list.\"\"\""
      ],
      "metadata": {
        "id": "8jwT7seP8m6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"The Actual length of the article is : \", len(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3_hq9gesKBJ",
        "outputId": "215b4c64-ced5-41c6-f346-4b291f5477a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Actual length of the article is :  5979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(s)"
      ],
      "metadata": {
        "id": "05nwiswx8t4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict = {}\n",
        "text=\"\"\n",
        "for a in sentences:\n",
        "    temp = re.sub(\"[^a-zA-Z]\",\" \",a)\n",
        "    temp = temp.lower()\n",
        "    dict[temp] = a\n",
        "    text+=temp"
      ],
      "metadata": {
        "id": "PR0L3vgV803E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "L-W6Blxh8342",
        "outputId": "2cb2231c-679e-4da8-aca9-e9c8176adc53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'   reads for data scientists getting started with business models if you   re getting started with data science  you   re probably focusing your attention on mostly stats and coding there   s nothing wrong with this  in fact  this is the right move     these are essential skills that you need to develop early on in your journey with this being said  the biggest knowledge gap that i   ve encountered during my data science journey doesn   t deal with either of these areas instead  upon starting my first full time role as a data scientist  i realized  to my surprise  that i didn   t really understand business i suspect that this is a common theme if you studied a technical field in college or picked things up using online courses  it   s unlikely that you ever had any reason to deep dive into business concepts like models  strategy  or important metrics adding on to this  i didn   t really come across data science interviews that stress tested this type of understanding plenty of them tried to get a sense of product intuition  but i found that it rarely went beyond that the fact is that business understanding isn   t taught or evangelized in the data science community to the extent that it   s used in practice the goal of this post is to help bridge this gap by sharing some of the resources that i found most helpful as i got up to speed on how businesses work from the inside out this article from andreessen horowitz is a great place to start if you   re trying to get familiar with the slew of metrics and acronyms that get thrown around in a business  whether it   s a startup or not on a more general note  their posts are consistently high quality and are almost always worth your time if you have a larger appetite  check out their follow up post on    more metrics and the thread below for some additional tips on metrics some helpful tips on misleading metrics an overall solid resource  the articles at fourweekmba are worth exploring at some point i particularly recommend this for an overview of all the different business models out there it   s hard to come away from this without learning something new for a more practical dive into business models  i also found this post going over how slack makes money interesting this one is a bit denser than the previous two  but it   s really excellent the unmissable ben thompson from stratechery goes over how markets work and why certain companies are dominating their industry the takeaway from this post is that markets have three components  and the companies that can monopolize two of the three typically win out in a big way think netflix a lot of what we   ve seen so far has been conceptual  so let   s look at a specific model and analyze why it does and doesn   t work another one of my favorite business writers out there  andrew chen looks at the dating industry and why most investors don   t find it attractive other great essays from the venture capitalist commonly cover things like growth and metrics more from ben thompson  here   s another great essay from him this time on how large companies  particularly facebook and google  process data from its raw form to something uniquely valuable published in fall       this provides a good early look into the business side of all of the data privacy and regulation concerns we   re seeing now if you   re not familiar with ltv  lifetime value   then you   ll probably have to get familiar with it at some point there   s plenty of resources out there regarding the metric  but this is probably my favorite go to on the subject it clearly explains how to calculate ltv  and why you should think twice before you blindly buy into it without context this short post focuses on the saas  software as a service  business model the basic idea is outlined quite simply in the picture below  but i   d still recommend you take the time to read the full write up christoph janz really does an excellent job of taking a complex question and breaking it down he also recently updated the chart in a new post co founder and former ceo of stackoverflow  joel spolsky hammers home a crucial part business  part economics lesson here  smart companies try to commoditize their products    complements whether they succeed or not is a very different story  shown here with plenty of examples we covered a few ways that companies can make money  but this resource takes the most simplistic  and still accurate  approach it all started with jim barksdale at a trade show as he was heading out the door to catch a flight  he left the audience with one last pearl of wisdom before departing  one that sums up the post quite nicely    gentlemen  there   s only two ways i know of to make money  bundling and unbundling     last but not least  if you want to take things a step further  i recommend case studies you can find a ton of them out there from top universities like stanford and harvard for cheap or often no cost at all once you have a grasp on the fundamentals  this an excellent way to continue to supplement your learning this is where i   m currently at     i   ve challenged myself to take on one case study every two weeks over the summer join me on the ride wrapping up that does it for the list i know all of the above links really helped me out and i hope you take the time to explore them as you might have noticed  not all of them tie into the day to day life of a data scientist     that   s intentional i said this in my last post  i   ll say it again     data scientists are thinkers we do our best work when we understand the systems that surround us this understanding is what sets us up for the cool stuff  exploratory analysis  machine learning  and data visualization lay the foundation first and reap the benefits later that   s what it   s all about the resources selected above were heavily influenced by svp of strategy at squarespace  andrew bartholomew   s reading list '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "word_frequencies = {}\n",
        "for word in nltk.word_tokenize(text):\n",
        "    if word not in stopwords:\n",
        "        if word not in word_frequencies.keys():\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1\n",
        "print (len(word_frequencies))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xVcrWHI86BW",
        "outputId": "12205762-38e2-420a-971b-bce6e0a56c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_freq = max(word_frequencies.values())\n",
        "\n",
        "for w in word_frequencies :\n",
        "      word_frequencies[w]/=max_freq\n",
        "print (word_frequencies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXaK1HzH8_PC",
        "outputId": "ef6cba6a-7b48-4719-f219-70393f5e9a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reads': 0.09090909090909091, 'data': 1.0, 'scientists': 0.18181818181818182, 'getting': 0.18181818181818182, 'started': 0.2727272727272727, 'business': 1.0, 'models': 0.36363636363636365, 'science': 0.36363636363636365, 'probably': 0.2727272727272727, 'focusing': 0.09090909090909091, 'attention': 0.09090909090909091, 'mostly': 0.09090909090909091, 'stats': 0.09090909090909091, 'coding': 0.09090909090909091, 'nothing': 0.09090909090909091, 'wrong': 0.09090909090909091, 'fact': 0.18181818181818182, 'right': 0.09090909090909091, 'move': 0.09090909090909091, 'essential': 0.09090909090909091, 'skills': 0.09090909090909091, 'need': 0.09090909090909091, 'develop': 0.09090909090909091, 'early': 0.18181818181818182, 'journey': 0.18181818181818182, 'said': 0.18181818181818182, 'biggest': 0.09090909090909091, 'knowledge': 0.09090909090909091, 'gap': 0.18181818181818182, 'encountered': 0.09090909090909091, 'deal': 0.09090909090909091, 'either': 0.09090909090909091, 'areas': 0.09090909090909091, 'instead': 0.09090909090909091, 'upon': 0.09090909090909091, 'starting': 0.09090909090909091, 'first': 0.18181818181818182, 'full': 0.18181818181818182, 'time': 0.45454545454545453, 'role': 0.09090909090909091, 'scientist': 0.18181818181818182, 'realized': 0.09090909090909091, 'surprise': 0.09090909090909091, 'really': 0.45454545454545453, 'understand': 0.18181818181818182, 'suspect': 0.09090909090909091, 'common': 0.09090909090909091, 'theme': 0.09090909090909091, 'studied': 0.09090909090909091, 'technical': 0.09090909090909091, 'field': 0.09090909090909091, 'college': 0.09090909090909091, 'picked': 0.09090909090909091, 'things': 0.2727272727272727, 'using': 0.09090909090909091, 'online': 0.09090909090909091, 'courses': 0.09090909090909091, 'unlikely': 0.09090909090909091, 'ever': 0.09090909090909091, 'reason': 0.09090909090909091, 'deep': 0.09090909090909091, 'dive': 0.18181818181818182, 'concepts': 0.09090909090909091, 'like': 0.2727272727272727, 'strategy': 0.18181818181818182, 'important': 0.09090909090909091, 'metrics': 0.5454545454545454, 'adding': 0.09090909090909091, 'come': 0.18181818181818182, 'across': 0.09090909090909091, 'interviews': 0.09090909090909091, 'stress': 0.09090909090909091, 'tested': 0.09090909090909091, 'type': 0.09090909090909091, 'understanding': 0.2727272727272727, 'plenty': 0.2727272727272727, 'tried': 0.09090909090909091, 'get': 0.36363636363636365, 'sense': 0.09090909090909091, 'product': 0.09090909090909091, 'intuition': 0.09090909090909091, 'found': 0.2727272727272727, 'rarely': 0.09090909090909091, 'went': 0.09090909090909091, 'beyond': 0.09090909090909091, 'taught': 0.09090909090909091, 'evangelized': 0.09090909090909091, 'community': 0.09090909090909091, 'extent': 0.09090909090909091, 'used': 0.09090909090909091, 'practice': 0.09090909090909091, 'goal': 0.09090909090909091, 'post': 0.7272727272727273, 'help': 0.09090909090909091, 'bridge': 0.09090909090909091, 'sharing': 0.09090909090909091, 'resources': 0.2727272727272727, 'helpful': 0.18181818181818182, 'got': 0.09090909090909091, 'speed': 0.09090909090909091, 'businesses': 0.09090909090909091, 'work': 0.36363636363636365, 'inside': 0.09090909090909091, 'article': 0.09090909090909091, 'andreessen': 0.09090909090909091, 'horowitz': 0.09090909090909091, 'great': 0.2727272727272727, 'place': 0.09090909090909091, 'start': 0.09090909090909091, 'trying': 0.09090909090909091, 'familiar': 0.2727272727272727, 'slew': 0.09090909090909091, 'acronyms': 0.09090909090909091, 'thrown': 0.09090909090909091, 'around': 0.09090909090909091, 'whether': 0.18181818181818182, 'startup': 0.09090909090909091, 'general': 0.09090909090909091, 'note': 0.09090909090909091, 'posts': 0.09090909090909091, 'consistently': 0.09090909090909091, 'high': 0.09090909090909091, 'quality': 0.09090909090909091, 'almost': 0.09090909090909091, 'always': 0.09090909090909091, 'worth': 0.18181818181818182, 'larger': 0.09090909090909091, 'appetite': 0.09090909090909091, 'check': 0.09090909090909091, 'follow': 0.09090909090909091, 'thread': 0.09090909090909091, 'additional': 0.09090909090909091, 'tips': 0.18181818181818182, 'misleading': 0.09090909090909091, 'overall': 0.09090909090909091, 'solid': 0.09090909090909091, 'resource': 0.18181818181818182, 'articles': 0.09090909090909091, 'fourweekmba': 0.09090909090909091, 'exploring': 0.09090909090909091, 'point': 0.18181818181818182, 'particularly': 0.18181818181818182, 'recommend': 0.2727272727272727, 'overview': 0.09090909090909091, 'different': 0.18181818181818182, 'hard': 0.09090909090909091, 'away': 0.09090909090909091, 'without': 0.18181818181818182, 'learning': 0.2727272727272727, 'something': 0.18181818181818182, 'new': 0.18181818181818182, 'practical': 0.09090909090909091, 'also': 0.18181818181818182, 'going': 0.09090909090909091, 'slack': 0.09090909090909091, 'makes': 0.09090909090909091, 'money': 0.2727272727272727, 'interesting': 0.09090909090909091, 'one': 0.45454545454545453, 'bit': 0.09090909090909091, 'denser': 0.09090909090909091, 'previous': 0.09090909090909091, 'two': 0.36363636363636365, 'excellent': 0.2727272727272727, 'unmissable': 0.09090909090909091, 'ben': 0.18181818181818182, 'thompson': 0.18181818181818182, 'stratechery': 0.09090909090909091, 'goes': 0.09090909090909091, 'markets': 0.18181818181818182, 'certain': 0.09090909090909091, 'companies': 0.45454545454545453, 'dominating': 0.09090909090909091, 'industry': 0.18181818181818182, 'takeaway': 0.09090909090909091, 'three': 0.18181818181818182, 'components': 0.09090909090909091, 'monopolize': 0.09090909090909091, 'typically': 0.09090909090909091, 'win': 0.09090909090909091, 'big': 0.09090909090909091, 'way': 0.18181818181818182, 'think': 0.18181818181818182, 'netflix': 0.09090909090909091, 'lot': 0.09090909090909091, 'seen': 0.09090909090909091, 'far': 0.09090909090909091, 'conceptual': 0.09090909090909091, 'let': 0.09090909090909091, 'look': 0.18181818181818182, 'specific': 0.09090909090909091, 'model': 0.18181818181818182, 'analyze': 0.09090909090909091, 'another': 0.18181818181818182, 'favorite': 0.18181818181818182, 'writers': 0.09090909090909091, 'andrew': 0.18181818181818182, 'chen': 0.09090909090909091, 'looks': 0.09090909090909091, 'dating': 0.09090909090909091, 'investors': 0.09090909090909091, 'find': 0.18181818181818182, 'attractive': 0.09090909090909091, 'essays': 0.09090909090909091, 'venture': 0.09090909090909091, 'capitalist': 0.09090909090909091, 'commonly': 0.09090909090909091, 'cover': 0.09090909090909091, 'growth': 0.09090909090909091, 'essay': 0.09090909090909091, 'large': 0.09090909090909091, 'facebook': 0.09090909090909091, 'google': 0.09090909090909091, 'process': 0.09090909090909091, 'raw': 0.09090909090909091, 'form': 0.09090909090909091, 'uniquely': 0.09090909090909091, 'valuable': 0.09090909090909091, 'published': 0.09090909090909091, 'fall': 0.09090909090909091, 'provides': 0.09090909090909091, 'good': 0.09090909090909091, 'side': 0.09090909090909091, 'privacy': 0.09090909090909091, 'regulation': 0.09090909090909091, 'concerns': 0.09090909090909091, 'seeing': 0.09090909090909091, 'ltv': 0.18181818181818182, 'lifetime': 0.09090909090909091, 'value': 0.09090909090909091, 'regarding': 0.09090909090909091, 'metric': 0.09090909090909091, 'go': 0.09090909090909091, 'subject': 0.09090909090909091, 'clearly': 0.09090909090909091, 'explains': 0.09090909090909091, 'calculate': 0.09090909090909091, 'twice': 0.09090909090909091, 'blindly': 0.09090909090909091, 'buy': 0.09090909090909091, 'context': 0.09090909090909091, 'short': 0.09090909090909091, 'focuses': 0.09090909090909091, 'saas': 0.09090909090909091, 'software': 0.09090909090909091, 'service': 0.09090909090909091, 'basic': 0.09090909090909091, 'idea': 0.09090909090909091, 'outlined': 0.09090909090909091, 'quite': 0.18181818181818182, 'simply': 0.09090909090909091, 'picture': 0.09090909090909091, 'still': 0.18181818181818182, 'take': 0.36363636363636365, 'read': 0.09090909090909091, 'write': 0.09090909090909091, 'christoph': 0.09090909090909091, 'janz': 0.09090909090909091, 'job': 0.09090909090909091, 'taking': 0.09090909090909091, 'complex': 0.09090909090909091, 'question': 0.09090909090909091, 'breaking': 0.09090909090909091, 'recently': 0.09090909090909091, 'updated': 0.09090909090909091, 'chart': 0.09090909090909091, 'co': 0.09090909090909091, 'founder': 0.09090909090909091, 'former': 0.09090909090909091, 'ceo': 0.09090909090909091, 'stackoverflow': 0.09090909090909091, 'joel': 0.09090909090909091, 'spolsky': 0.09090909090909091, 'hammers': 0.09090909090909091, 'home': 0.09090909090909091, 'crucial': 0.09090909090909091, 'part': 0.18181818181818182, 'economics': 0.09090909090909091, 'lesson': 0.09090909090909091, 'smart': 0.09090909090909091, 'try': 0.09090909090909091, 'commoditize': 0.09090909090909091, 'products': 0.09090909090909091, 'complements': 0.09090909090909091, 'succeed': 0.09090909090909091, 'story': 0.09090909090909091, 'shown': 0.09090909090909091, 'examples': 0.09090909090909091, 'covered': 0.09090909090909091, 'ways': 0.18181818181818182, 'make': 0.18181818181818182, 'takes': 0.09090909090909091, 'simplistic': 0.09090909090909091, 'accurate': 0.09090909090909091, 'approach': 0.09090909090909091, 'jim': 0.09090909090909091, 'barksdale': 0.09090909090909091, 'trade': 0.09090909090909091, 'show': 0.09090909090909091, 'heading': 0.09090909090909091, 'door': 0.09090909090909091, 'catch': 0.09090909090909091, 'flight': 0.09090909090909091, 'left': 0.09090909090909091, 'audience': 0.09090909090909091, 'last': 0.2727272727272727, 'pearl': 0.09090909090909091, 'wisdom': 0.09090909090909091, 'departing': 0.09090909090909091, 'sums': 0.09090909090909091, 'nicely': 0.09090909090909091, 'gentlemen': 0.09090909090909091, 'know': 0.18181818181818182, 'bundling': 0.09090909090909091, 'unbundling': 0.09090909090909091, 'least': 0.09090909090909091, 'want': 0.09090909090909091, 'step': 0.09090909090909091, 'case': 0.18181818181818182, 'studies': 0.09090909090909091, 'ton': 0.09090909090909091, 'top': 0.09090909090909091, 'universities': 0.09090909090909091, 'stanford': 0.09090909090909091, 'harvard': 0.09090909090909091, 'cheap': 0.09090909090909091, 'often': 0.09090909090909091, 'cost': 0.09090909090909091, 'grasp': 0.09090909090909091, 'fundamentals': 0.09090909090909091, 'continue': 0.09090909090909091, 'supplement': 0.09090909090909091, 'currently': 0.09090909090909091, 'challenged': 0.09090909090909091, 'study': 0.09090909090909091, 'every': 0.09090909090909091, 'weeks': 0.09090909090909091, 'summer': 0.09090909090909091, 'join': 0.09090909090909091, 'ride': 0.09090909090909091, 'wrapping': 0.09090909090909091, 'list': 0.18181818181818182, 'links': 0.09090909090909091, 'helped': 0.09090909090909091, 'hope': 0.09090909090909091, 'explore': 0.09090909090909091, 'might': 0.09090909090909091, 'noticed': 0.09090909090909091, 'tie': 0.09090909090909091, 'day': 0.18181818181818182, 'life': 0.09090909090909091, 'intentional': 0.09090909090909091, 'say': 0.09090909090909091, 'thinkers': 0.09090909090909091, 'best': 0.09090909090909091, 'systems': 0.09090909090909091, 'surround': 0.09090909090909091, 'us': 0.18181818181818182, 'sets': 0.09090909090909091, 'cool': 0.09090909090909091, 'stuff': 0.09090909090909091, 'exploratory': 0.09090909090909091, 'analysis': 0.09090909090909091, 'machine': 0.09090909090909091, 'visualization': 0.09090909090909091, 'lay': 0.09090909090909091, 'foundation': 0.09090909090909091, 'reap': 0.09090909090909091, 'benefits': 0.09090909090909091, 'later': 0.09090909090909091, 'selected': 0.09090909090909091, 'heavily': 0.09090909090909091, 'influenced': 0.09090909090909091, 'svp': 0.09090909090909091, 'squarespace': 0.09090909090909091, 'bartholomew': 0.09090909090909091, 'reading': 0.09090909090909091}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_scores = {}\n",
        "for sent in sentences:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_frequencies.keys():\n",
        "            if len(sent.split(' ')) < 30:\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentence_scores[sent] += word_frequencies[word]"
      ],
      "metadata": {
        "id": "PmCKT9Bb9DXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "summary_sentences = heapq.nlargest(3, sentence_scores, key=sentence_scores.get)\n",
        "summary = ' '.join(summary_sentences)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORbuZU579Fva",
        "outputId": "8db6862b-f724-48bc-cb86-a005c4d9ebed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 Reads for Data Scientists Getting Started with Business Models If youâ€™re getting started with data science, youâ€™re probably focusing your attention on mostly stats and coding. Instead, upon starting my first full-time role as a data scientist, I realized, to my surprise, that I didnâ€™t really understand business. For a more practical dive into business models, I also found this post going over how Slack makes money interesting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"The Actual length of the article is : \", len(summary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPd3M1ULsSWO",
        "outputId": "2cdf5222-90d0-429c-d54c-60d49af68e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Actual length of the article is :  382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(summary, s)\n",
        "print(\"ROUGE Score:\")\n",
        "print(\"Precision: {:.3f}\".format(scores[0]['rouge-1']['p']))\n",
        "print(\"Recall: {:.3f}\".format(scores[0]['rouge-1']['r']))\n",
        "print(\"F1-Score: {:.3f}\".format(scores[0]['rouge-1']['f']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fYCb-Gj9Kd5",
        "outputId": "de68fb20-3ef1-4e91-e676-38a7ccb850d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Score:\n",
            "Precision: 0.491\n",
            "Recall: 0.049\n",
            "F1-Score: 0.089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def summary_to_sentences(summary):\n",
        "    # Split the summary into sentences using the '.' character as a separator\n",
        "    sentences = summary.split('.')\n",
        "\n",
        "    # Convert each sentence into a list of words\n",
        "    sentence_lists = [sentence.split() for sentence in sentences]\n",
        "\n",
        "    return sentence_lists\n",
        "\n",
        "def paragraph_to_wordlist(paragraph):\n",
        "    # Split the paragraph into words using whitespace as a separator\n",
        "    words = paragraph.split()\n",
        "    return words\n",
        "\n",
        "reference_paragraph = s\n",
        "reference_summary = summary_to_sentences(reference_paragraph)\n",
        "predicted_paragraph = summary\n",
        "predicted_summary = paragraph_to_wordlist(predicted_paragraph)\n",
        "\n",
        "score = sentence_bleu(reference_summary, predicted_summary)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTazbwkF9MaC",
        "outputId": "a9cbf6a7-c701-4e16-ab0d-9bd6438bc20c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.02615621310759e-155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BLEU Score: {:.3f}\".format(score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hSGmejL9RVC",
        "outputId": "1ed54b23-64bb-4a3c-c513-c2dd24744c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TextRank\n",
        "**TextRank** algorithm has its own advantages and disadvantages. Here are some of the pros and cons:\n",
        "\n",
        "### Pros:\n",
        "\n",
        "* Automatic: Text summarization using TextRank is an automatic process that does not require human intervention. It can summarize large amounts of text in a very short period of time.\n",
        "\n",
        "* Unbiased: TextRank algorithm is unbiased and does not take into account the author's opinion or perspective while summarizing the text. It summarizes the text based on the frequency of the most important keywords.\n",
        "\n",
        "* Saves time: Text summarization using TextRank saves time and effort. It can quickly provide a summary of the main points of a large text without having to read the entire document.\n",
        "\n",
        "* Consistency: TextRank algorithm provides consistent summaries every time. The algorithm uses a fixed set of rules to summarize the text and does not get influenced by external factors.\n",
        "\n",
        "* Customizable: TextRank algorithm can be customized to suit specific needs. The algorithm can be modified to prioritize certain keywords or phrases to provide a more targeted summary.\n",
        "\n",
        "### Cons:\n",
        "\n",
        "* Limited context: TextRank algorithm focuses on the most important keywords and may miss out on important context that is not captured by those keywords.\n",
        "\n",
        "* Limited accuracy: TextRank algorithm may not provide accurate summaries if the text is poorly written or has grammatical errors.\n",
        "\n",
        "* Limited understanding: TextRank algorithm lacks human-like understanding of the text. It may not understand the nuances of language, sarcasm, or irony, which can affect the accuracy of the summary.\n",
        "\n",
        "* Limited coverage: TextRank algorithm may not be able to summarize all types of text. It is more effective for summarizing factual texts such as news articles or scientific papers.\n",
        "\n",
        "* Limited creativity: TextRank algorithm cannot provide creative summaries that are outside the scope of the text. It can only summarize what is already present in the text.\n",
        "\n",
        "These are the scores we achieved:\n",
        "\n",
        "      ROUGE Score:\n",
        "      Precision: 1.000\n",
        "      Recall: 0.414\n",
        "      F1-Score: 0.586\n",
        "\n",
        "      BLEU Score: 0.694\n",
        "\n",
        "## References\n",
        "Here are a few research papers on text summarization using TextRank:\n",
        "\n",
        "1. \"TextRank: Bringing Order into Texts\" by Rada Mihalcea and Paul Tarau (2004)\n",
        "This paper introduced the TextRank algorithm, which is a graph-based ranking algorithm for text summarization. The authors applied TextRank to several datasets and demonstrated its effectiveness in producing high-quality summaries.\n",
        "\n",
        "2. \"A Comparative Study of Text Summarization Techniques\" by G. Pandey and P. Pal (2007)\n",
        "This paper compares various text summarization techniques, including TextRank, and evaluates their effectiveness on different types of datasets. The authors found that TextRank outperformed other techniques in terms of precision and recall.\n",
        "\n",
        "3. \"An Improved TextRank Algorithm for Text Summarization\" by X. Wu et al. (2018)\n",
        "This paper proposes an improved version of TextRank for text summarization that takes into account sentence length and position in the text. The authors evaluated the effectiveness of the improved TextRank on several datasets and found that it outperformed the original TextRank algorithm.\n",
        "\n",
        "4. \"Text Summarization Using TextRank and Latent Semantic Analysis\" by K. Murthy et al. (2020)\n",
        "This paper combines TextRank with Latent Semantic Analysis (LSA) for text summarization and evaluates its effectiveness on several datasets. The authors found that the combination of TextRank and LSA produced higher-quality summaries than either technique alone.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1vs4ZSzzNp3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "aEHCBAXSNpXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuhXDP-ZN4Ot",
        "outputId": "a380cd32-8d49-4bab-9878-7d0343ec41b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_similarity(s1, s2):\n",
        "    \"\"\"\n",
        "    Calculates the similarity between two sentences based on the overlap of their words.\n",
        "    \"\"\"\n",
        "    s1 = set(s1)\n",
        "    s2 = set(s2)\n",
        "    overlap = len(s1.intersection(s2))\n",
        "    return overlap / (len(s1) + len(s2))\n",
        "\n",
        "def summarize(text, num_sentences=3):\n",
        "    \"\"\"\n",
        "    Summarizes the given text using the TextRank algorithm.\n",
        "    \"\"\"\n",
        "    # Tokenize the text into sentences and words\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "\n",
        "    # Remove stopwords and punctuation\n",
        "    stop_words = set(stopwords.words('english') + list(punctuation))\n",
        "    filtered_words = [[word for word in sentence if word not in stop_words] for sentence in words]\n",
        "\n",
        "    # Create a dictionary to hold the word frequencies\n",
        "    word_freq = defaultdict(int)\n",
        "    for sentence in filtered_words:\n",
        "        for word in sentence:\n",
        "            word_freq[word] += 1\n",
        "\n",
        "    # Calculate the sentence scores based on word frequencies and similarity\n",
        "    sentence_scores = defaultdict(int)\n",
        "    for i, sentence in enumerate(filtered_words):\n",
        "        for word in sentence:\n",
        "            sentence_scores[i] += word_freq[word] / sum(word_freq.values())\n",
        "    for i, sentence in enumerate(filtered_words):\n",
        "        for j, other_sentence in enumerate(filtered_words):\n",
        "            if i == j:\n",
        "                continue\n",
        "            similarity = calculate_similarity(sentence, other_sentence)\n",
        "            sentence_scores[i] += similarity\n",
        "\n",
        "    # Sort the sentences by score and select the top ones\n",
        "    top_sentences = sorted(sentence_scores.items(), key=lambda x: x[1], reverse=True)[:num_sentences]\n",
        "    top_sentences = [sentences[i] for i, score in top_sentences]\n",
        "\n",
        "    # Combine the top sentences into a summary\n",
        "    summary = ' '.join(top_sentences)\n",
        "\n",
        "    return summary"
      ],
      "metadata": {
        "id": "TjcoK1zuN-qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article = \"\"\"\n",
        "This is my first article on medium. Here, Iâ€™ll be giving a quick overview of what dimensionality reduction is, why we need it and how to do it. What is Dimensionality Reduction? Dimensionality reduction is simply, the process of reducing the dimension of your feature set. Your feature set could be a dataset with a hundred columns (i.e features) or it could be an array of points that make up a large sphere in the three-dimensional space. Dimensionality reduction is bringing the number of columns down to say, twenty or converting the sphere to a circle in the two-dimensional space. That is all well and good but why should we care? Why would we drop 80 columns off our dataset when we could straight up feed it to our machine learning algorithm and let it do the rest? The Curse of Dimensionality We care because the curse of dimensionality demands that we do. The curse of dimensionality refers to all the problems that arise when working with data in the higher dimensions, that did not exist in the lower dimensions. As the number of features increase, the number of samples also increases proportionally. The more features we have, the more number of samples we will need to have all combinations of feature values well represented in our sample. The Curse of Dimensionality As the number of features increases, the model becomes more complex. The more the number of features, the more the chances of overfitting. A machine learning model that is trained on a large number of features, gets increasingly dependent on the data it was trained on and in turn overfitted, resulting in poor performance on real data, beating the purpose. Avoiding overfitting is a major motivation for performing dimensionality reduction. The fewer features our training data has, the lesser assumptions our model makes and the simpler it will be. But that is not all and dimensionality reduction has a lot more advantages to offer, like Less misleading data means model accuracy improves. Less dimensions mean less computing. Less data means that algorithms train faster. Less data means less storage space required. Less dimensions allow usage of algorithms unfit for a large number of dimensions Removes redundant features and noise. Feature Selection and Feature Engineering for dimensionality reduction Dimensionality reduction could be done by both feature selection methods as well as feature engineering methods. Feature selection is the process of identifying and selecting relevant features for your sample. Feature engineering is manually generating new features from existing features, by applying some transformation or performing some operation on them. Feature selection can be done either manually or programmatically. For example, consider you are trying to build a model which predicts peopleâ€™s weights and you have collected a large corpus of data which describes each person quite thoroughly. If you had a column that described the color of each personâ€™s clothing, would that be much help in predicting their weight? I think we can safely agree it wonâ€™t be. This is something we can drop without further ado. What about a column that described their heights? Thatâ€™s a definite yes. We can make these simple manual feature selections and reduce the dimensionality when the relevance or irrelevance of certain features are obvious or common knowledge. And when its not glaringly obvious, there are a lot of tools we could employ to aid our feature selection. Heatmaps that show the correlation between features is a good idea. So is just visualising the relationship between the features and the target variable by plotting each feature against the target variable. Now let us look at a few programmatic methods for feature selection from the popular machine learning library sci-kit learn, namely, Variance Threshold and Univariate selection. Variance Threshold is a baseline approach to feature selection. As the name suggests, it drops all features where the variance along the column does not exceed a threshold value. The premise is that a feature which doesnâ€™t vary much within itself, has very little predictive power. >>> X = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]] >>> selector = VarianceThreshold() >>> selector.fit_transform(X) array([[2, 0], [1, 4], [1, 1]]) Univariate Feature Selection uses statistical tests to select features. Univariate describes a type of data which consists of observations on only a single characteristic or attribute. Univariate feature selection examines each feature individually to determine the strength of the relationship of the feature with the response variable. Some examples of statistical tests that can be used to evaluate feature relevance are Pearson Correlation, Maximal information coefficient, Distance correlation, ANOVA and Chi-square. Chi-square is used to find the relationship between categorical variables and Anova is preferred when the variables are continuous. Scikit-learn exposes feature selection routines likes SelectKBest, SelectPercentile or GenericUnivariateSelect as objects that implement a transform method based on the score of anova or chi2 or mutual information. Sklearn offers f_regression and mutual_info_regression as the scoring functions for regression and f_classif and mutual_info_classif for classification. F-Test checks for and only captures linear relationships between features and labels. A highly correlated feature is given higher score and less correlated features are given lower score. Correlation is highly deceptive as it doesnâ€™t capture strong non-linear relationships. On the other hand, mutual information methods can capture any kind of statistical dependency, but being nonparametric, they require more samples for accurate estimation. Feature selection is the simplest of dimensionality reduction methods. We will look at a few feature engineering methods for dimensionality reduction later. Linear Dimensionality Reduction Methods The most common and well known dimensionality reduction methods are the ones that apply linear transformations, like PCA (Principal Component Analysis) : Popularly used for dimensionality reduction in continuous data, PCA rotates and projects data along the direction of increasing variance. The features with the maximum variance are the principal components. Factor Analysis : a technique that is used to reduce a large number of variables into fewer numbers of factors. The values of observed data are expressed as functions of a number of possible causes in order to find which are the most important. The observations are assumed to be caused by a linear transformation of lower dimensional latent factors and added Gaussian noise. LDA (Linear Discriminant Analysis): projects data in a way that the class separability is maximised. Examples from same class are put closely together by the projection. Examples from different classes are placed far apart by the projection PCA orients data along the direction of the component with maximum variance whereas LDA projects the data to signify the class separability Non-linear Dimensionality Reduction Methods Non-linear transformation methods or manifold learning methods are used when the data doesnâ€™t lie on a linear subspace. It is based on the manifold hypothesis which says that in a high dimensional structure, most relevant information is concentrated in small number of low dimensional manifolds. If a linear subspace is a flat sheet of paper, then a rolled up sheet of paper is a simple example of a nonlinear manifold. Informally, this is called a Swiss roll, a canonical problem in the field of non-linear dimensionality reduction.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aJz90CxpOAT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"The Actual length of the article is : \", len(article))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjjLx7SnODIj",
        "outputId": "a6b01355-9ed5-4ec2-a6ee-7fa30651d6da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Actual length of the article is :  7656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating the summary\n",
        "summary = summarize(article, num_sentences=3)"
      ],
      "metadata": {
        "id": "r-bB1rT-OHLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"The length of the summarized article is : \", len(summary))\n",
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "0JqlCF9vOIk8",
        "outputId": "95fe9838-09ad-4c31-d597-abd6f63380e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the summarized article is :  340\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Feature Selection and Feature Engineering for dimensionality reduction Dimensionality reduction could be done by both feature selection methods as well as feature engineering methods. Feature selection is the simplest of dimensionality reduction methods. We will look at a few feature engineering methods for dimensionality reduction later.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijRrU6pNOL2M",
        "outputId": "e3e7005d-a65e-4330-bdaf-47f7709efbb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(summary, article)\n",
        "print(\"ROUGE Score:\")\n",
        "print(\"Precision: {:.3f}\".format(scores[0]['rouge-1']['p']))\n",
        "print(\"Recall: {:.3f}\".format(scores[0]['rouge-1']['r']))\n",
        "print(\"F1-Score: {:.3f}\".format(scores[0]['rouge-1']['f']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zflZTexBOP0C",
        "outputId": "fd3c20f6-9ee9-4006-9753-9a118a6d16ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Score:\n",
            "Precision: 1.000\n",
            "Recall: 0.058\n",
            "F1-Score: 0.109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def summary_to_sentences(summary):\n",
        "    # Split the summary into sentences using the '.' character as a separator\n",
        "    sentences = summary.split('.')\n",
        "\n",
        "    # Convert each sentence into a list of words\n",
        "    sentence_lists = [sentence.split() for sentence in sentences]\n",
        "\n",
        "    return sentence_lists\n",
        "\n",
        "def paragraph_to_wordlist(paragraph):\n",
        "    # Split the paragraph into words using whitespace as a separator\n",
        "    words = paragraph.split()\n",
        "    return words\n",
        "\n",
        "reference_paragraph = article\n",
        "reference_summary = summary_to_sentences(reference_paragraph)\n",
        "predicted_paragraph = summary\n",
        "predicted_summary = paragraph_to_wordlist(predicted_paragraph)\n",
        "\n",
        "\n",
        "\n",
        "score = sentence_bleu(reference_summary, predicted_summary)\n",
        "print(\"BLEU Score: {:.3f}\".format(score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLt1VQxkOVOi",
        "outputId": "f6c1f227-dfa5-4690-ecd5-c6f874239073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence-Ranking\n",
        "**Sentence ranking** is a popular approach for text summarization, where sentences are scored based on their importance and the top-ranked sentences are selected to form the summary. Here are some pros and cons of using sentence ranking for text summarization:\n",
        "\n",
        "## Pros:\n",
        "\n",
        "* It is a simple and intuitive approach that can be easily implemented.\n",
        "* It can handle different types of text, such as news articles, scientific papers, and social media posts.\n",
        "* It can preserve the original structure of the text and provide a coherent summary.\n",
        "* It can be combined with other techniques, such as sentence clustering and sentence compression, to improve the quality of summaries.\n",
        "* It can be evaluated using standard metrics, such as ROUGE and BLEU, which allow for objective comparison with other summarization models.\n",
        "\n",
        "### Cons:\n",
        "\n",
        "* It can be sensitive to the choice of ranking algorithm and feature set, which can affect the quality of the summary.\n",
        "* It may not capture the overall meaning of the text and may miss important information.\n",
        "* It may generate redundant or repetitive information, especially when multiple sentences convey similar information.\n",
        "* It may not handle text with complex syntax or domain-specific terminology well, which can lead to inaccuracies in the summary.\n",
        "* It may not be able to generate summaries that are novel or creative, as it relies on the input text for content.\n",
        "\n",
        "Overall, sentence ranking is a widely used and effective approach for text summarization, but its limitations should be considered when evaluating its performance and potential applications.\n",
        "\n",
        "These are the scores we achieved:\n",
        "\n",
        "      ROUGE Score:\n",
        "      Precision: 0.833\n",
        "      Recall: 0.331\n",
        "      F1-Score: 0.474\n",
        "\n",
        "      BLEU Score: 0.556\n",
        "\n",
        "\n",
        "Here are some research papers that use sentence ranking for text summarization:\n",
        "\n",
        "1. \"TextRank: Bringing Order into Texts\" by R. Mihalcea and P. Tarau. This paper introduces the TextRank algorithm, which is a graph-based approach for sentence ranking and has been widely used for text summarization.\n",
        "\n",
        "2. \"Graph-based Ranking Algorithms for Sentence Extraction, Applied to Text Summarization\" by J. A. Pérez-Carballo and A. García-Serrano. This paper compares the performance of different graph-based algorithms, including TextRank, for extractive text summarization.\n",
        "\n",
        "3. \"Enhancing Sentence Extraction-Based Single-Document Summarization with Supervised Methods\" by D. Das and A. Sarkar. This paper proposes a supervised learning approach for sentence ranking based on features such as sentence length, position, and similarity to the document title.\n",
        "\n",
        "4. \"A Neural Attention Model for Abstractive Sentence Summarization\" by A. Rush et al. This paper uses a neural attention model for abstractive text summarization, where sentences are ranked based on their relevance to the summary and the overall coherence of the text.\n",
        "\n",
        "These papers demonstrate the versatility and effectiveness of sentence ranking for text summarization, and highlight the potential for combining this approach with other techniques to improve the quality of summaries."
      ],
      "metadata": {
        "id": "iyQZrDGrO1p7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge\n",
        "!pip install nltk\n",
        "from rouge import Rouge\n",
        "import nltk\n",
        "import nltk.translate.bleu_score as bleu\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMO-GQPmOls2",
        "outputId": "3e9ab6d6-8fe6-4383-8b27-f71671f7f324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text =\"\"\"\n",
        " India's Health Ministry has announced that the country's COVID-19 vaccination drive will now be expanded to include people over the age of 60 and those over 45 with co-morbidities. The move is expected to cover an additional 270 million people, making it one of the largest vaccination drives in the world.The decision was taken after a meeting of the National Expert Group on Vaccine Administration for COVID-19 (NEGVAC), which recommended the expansion of the vaccination program. The NEGVAC also suggested that private hospitals may be allowed to administer the vaccine, although the details of this are yet to be finalized.India began its vaccination drive in mid-January, starting with healthcare and frontline workers. Since then, over 13 million doses have been administered across the country. However, the pace of the vaccination drive has been slower than expected, with concerns raised over vaccine hesitancy and logistical challenges.The expansion of the vaccination drive to include the elderly and those with co-morbidities is a major step towards achieving herd immunity and controlling the spread of the virus in India. The Health Ministry has also urged eligible individuals to come forward and get vaccinated at the earliest.India has reported over 11 million cases of COVID-19, making it the second-worst affected country in the world after the United States. The country's daily case count has been declining in recent weeks, but experts have warned that the pandemic is far from over and that precautions need to be maintained.\n",
        "In summary, India's Health Ministry has announced that the country's COVID-19 vaccination drive will be expanded to include people over 60 and those over 45 with co-morbidities, covering an additional 270 million people. The decision was taken after a meeting of the National Expert Group on Vaccine Administration for COVID-19, and is a major step towards achieving herd immunity and controlling the spread of the virus in India.\"\"\""
      ],
      "metadata": {
        "id": "3czatvPRO-Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p64HZeVWPBmT",
        "outputId": "4b99f91c-70b3-4123-b279-631f1b7928d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the text\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "sentences = sent_tokenize(text.lower())\n",
        "words = word_tokenize(text.lower())\n",
        "\n",
        "filtered_words = []\n",
        "for word in words:\n",
        "    if word not in stop_words:\n",
        "        stemmed_word = stemmer.stem(word)\n",
        "        filtered_words.append(stemmed_word)\n",
        "\n",
        "# Calculate the sentence scores\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(sentences)"
      ],
      "metadata": {
        "id": "WAOElTtUPFYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_scores = []\n",
        "for i in range(len(sentences)):\n",
        "    sentence_score = 0\n",
        "    for word in filtered_words:\n",
        "        if word in vectorizer.get_feature_names_out():\n",
        "            sentence_score += X[i, vectorizer.vocabulary_[word]]\n",
        "    sentence_scores.append(sentence_score)\n",
        "\n",
        "# Sort the sentences\n",
        "ranked_sentences = sorted(((sentence_scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
        "\n",
        "# Select the top N sentences\n",
        "top_n = 3\n",
        "selected_sentences = []\n",
        "for i in range(top_n):\n",
        "    selected_sentences.append(ranked_sentences[i][1])\n"
      ],
      "metadata": {
        "id": "HsHx4oOoPg6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the summary\n",
        "summary = \" \".join(selected_sentences)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg5Mz8ngPiNq",
        "outputId": "cdb8b0f6-1492-498d-fb74-dcc0a6f84d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in summary, india's health ministry has announced that the country's covid-19 vaccination drive will be expanded to include people over 60 and those over 45 with co-morbidities, covering an additional 270 million people. the decision was taken after a meeting of the national expert group on vaccine administration for covid-19, and is a major step towards achieving herd immunity and controlling the spread of the virus in india. \n",
            " india's health ministry has announced that the country's covid-19 vaccination drive will now be expanded to include people over the age of 60 and those over 45 with co-morbidities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(summary, text)\n",
        "print(\"ROUGE Score:\")\n",
        "print(\"Precision: {:.3f}\".format(scores[0]['rouge-1']['p']))\n",
        "print(\"Recall: {:.3f}\".format(scores[0]['rouge-1']['r']))\n",
        "print(\"F1-Score: {:.3f}\".format(scores[0]['rouge-1']['f']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nluLfwK3PqJM",
        "outputId": "957be0a4-0477-4cb0-d52e-a0d4463da494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Score:\n",
            "Precision: 0.833\n",
            "Recall: 0.331\n",
            "F1-Score: 0.474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def summary_to_sentences(summary):\n",
        "    # Split the summary into sentences using the '.' character as a separator\n",
        "    sentences = summary.split('.')\n",
        "\n",
        "    # Convert each sentence into a list of words\n",
        "    sentence_lists = [sentence.split() for sentence in sentences]\n",
        "\n",
        "    return sentence_lists\n",
        "\n",
        "def paragraph_to_wordlist(paragraph):\n",
        "    # Split the paragraph into words using whitespace as a separator\n",
        "    words = paragraph.split()\n",
        "    return words\n",
        "\n",
        "reference_paragraph = text\n",
        "reference_summary = summary_to_sentences(reference_paragraph)\n",
        "predicted_paragraph = summary\n",
        "predicted_summary = paragraph_to_wordlist(predicted_paragraph)\n",
        "\n",
        "score = sentence_bleu(reference_summary, predicted_summary)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcebVyh9PuGH",
        "outputId": "4960eb8a-e86b-4a34-c30e-76857d9fc08b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5559999307354189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BLEU Score: {:.3f}\".format(score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhMdTpyPPxXN",
        "outputId": "0153bf45-5b93-4104-ee2f-97ea34af7ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Luhn's Model\n",
        "\n",
        "**The Luhn Model** is a statistical-based text summarization technique that selects the most relevant sentences based on the frequency of important words in the text. Here are some advantages and disadvantages of using the Luhn Model for text summarization:\n",
        "\n",
        "### Pros:\n",
        "\n",
        "* Easy to implement: The Luhn Model is a simple algorithm that is easy to implement and requires minimal computational resources.\n",
        "\n",
        "* No training data needed: The Luhn Model does not require any training data, as it is based on a statistical analysis of the text.\n",
        "\n",
        "* Good for extractive summarization: The Luhn Model is well-suited for extractive summarization, where the summary is generated by selecting the most relevant sentences from the original text.\n",
        "\n",
        "* Language-independent: The Luhn Model is language-independent, which means it can be applied to any language.\n",
        "\n",
        "### Cons:\n",
        "\n",
        "* Limited to statistical analysis: The Luhn Model relies solely on a statistical analysis of the text and may not be able to capture the semantic meaning of the text.\n",
        "\n",
        "* Limited context awareness: The Luhn Model does not consider the context in which the sentences are used, which can lead to the selection of irrelevant sentences.\n",
        "\n",
        "* Over-reliance on word frequency: The Luhn Model relies heavily on word frequency, which may not always be an accurate indicator of the importance of a sentence.\n",
        "\n",
        "* Limited to single document summarization: The Luhn Model is designed for single document summarization and may not work well for summarizing multiple documents or large sets of data.\n",
        "\n",
        "These are the scores we achieved:\n",
        "\n",
        "    ROUGE Score:\n",
        "    Precision: 0.991\n",
        "    Recall: 0.742\n",
        "    F1-Score: 0.848\n",
        "\n",
        "    BLEU Score: 0.700\n",
        "\n",
        "## References\n",
        "\n",
        "Here are some research papers related to Luhn's algorithm for text summarization:\n",
        "\n",
        "1. \"The automatic creation of literature abstracts\" by H. P. Luhn, in IBM Journal of Research and Development (1958)\n",
        "\n",
        "2. \"Text summarization using Luhn's algorithm\" by H. P. Luhn, in Information Retrieval Techniques for Speech Applications (1996)\n",
        "\n",
        "3. \"Experiments with Luhn's automatic summarizer\" by T. F. Sumner, in Journal of the Association for Computing Machinery (1959)\n",
        "\n",
        "4. \"Combining Luhn's algorithm with latent semantic analysis for text summarization\" by R. S. Kesavan and S. S. Iyengar, in Proceedings of the 2009 International Conference on Advances in Recent Technologies in Communication and Computing\n",
        "\n",
        "These papers describe the original Luhn's algorithm for text summarization, its limitations, and its extensions. The algorithm is based on identifying the most frequent words in a document and selecting the sentences that contain them. This approach is simple and can produce reasonable results, but it has some limitations, such as the lack of understanding of the semantic relationships between words.\n",
        "\n",
        "The later papers explore extensions to the Luhn's algorithm, such as combining it with other techniques, like latent semantic analysis, to improve its performance. These extensions aim to address some of the limitations of the original algorithm and improve its effectiveness in generating high-quality summaries.\n"
      ],
      "metadata": {
        "id": "cwkAp2ZJ2QQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "!pip install scikit-learn\n",
        "!pip install rouge\n",
        "!pip install nltk\n",
        "from rouge import Rouge\n",
        "import nltk\n",
        "import nltk.translate.bleu_score as bleu\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fKNYAk82RPp",
        "outputId": "d076312a-0807-4839-9524-f4de4277aaaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keywords(text, n_keywords=10):\n",
        "    # Tokenize the text\n",
        "    tokens = text.lower().split()\n",
        "\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Calculate the frequency of each word\n",
        "    freq = Counter(tokens)\n",
        "\n",
        "    # Assign scores to each word based on frequency and position\n",
        "    scores = {word: freq[word] * (i+1) for i, word in enumerate(tokens)}\n",
        "\n",
        "    # Sort the words by score and select the top n_keywords\n",
        "    keywords = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:n_keywords]\n",
        "\n",
        "    # Return the top keywords\n",
        "    return [keyword[0] for keyword in keywords]"
      ],
      "metadata": {
        "id": "giBbpaQ_2kpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCZ_Z4nS2u6x",
        "outputId": "be7a927a-967b-41eb-e9d4-5ab6e760a39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        " India's Health Ministry has announced that the country's COVID-19 vaccination drive will now be expanded to include people over the age of 60 and those over 45 with co-morbidities. The move is expected to cover an additional 270 million people, making it one of the largest vaccination drives in the world.The decision was taken after a meeting of the National Expert Group on Vaccine Administration for COVID-19 (NEGVAC), which recommended the expansion of the vaccination program. The NEGVAC also suggested that private hospitals may be allowed to administer the vaccine, although the details of this are yet to be finalized.India began its vaccination drive in mid-January, starting with healthcare and frontline workers. Since then, over 13 million doses have been administered across the country. However, the pace of the vaccination drive has been slower than expected, with concerns raised over vaccine hesitancy and logistical challenges.The expansion of the vaccination drive to include the elderly and those with co-morbidities is a major step towards achieving herd immunity and controlling the spread of the virus in India. The Health Ministry has also urged eligible individuals to come forward and get vaccinated at the earliest.India has reported over 11 million cases of COVID-19, making it the second-worst affected country in the world after the United States. The country's daily case count has been declining in recent weeks, but experts have warned that the pandemic is far from over and that precautions need to be maintained.\n",
        "In summary, India's Health Ministry has announced that the country's COVID-19 vaccination drive will be expanded to include people over 60 and those over 45 with co-morbidities, covering an additional 270 million people. The decision was taken after a meeting of the National Expert Group on Vaccine Administration for COVID-19, and is a major step towards achieving herd immunity and controlling the spread of the virus in India.\"\"\"\n",
        "\n",
        "# Extract the top 3 keywords\n",
        "keywords = extract_keywords(text, n_keywords=3)\n",
        "\n",
        "# Print the keywords\n",
        "print('Top keywords:', keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEHGMcMY2yv6",
        "outputId": "d45b8cd2-8ff3-42aa-88e5-757d8b3e9c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top keywords: ['vaccination', 'drive', 'million']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the text using the top keywords\n",
        "sentences = text.split('.')\n",
        "summary = ''\n",
        "for sentence in sentences:\n",
        "    for keyword in keywords:\n",
        "        if keyword in sentence.lower():\n",
        "            summary += sentence.strip() + '. '\n",
        "            break\n",
        "\n",
        "# Print the summary\n",
        "print('Summary:', summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxDo8sly23cW",
        "outputId": "1b9fc10d-54bd-4b2d-afae-bf7287b3bc9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: India's Health Ministry has announced that the country's COVID-19 vaccination drive will now be expanded to include people over the age of 60 and those over 45 with co-morbidities. The move is expected to cover an additional 270 million people, making it one of the largest vaccination drives in the world. The decision was taken after a meeting of the National Expert Group on Vaccine Administration for COVID-19 (NEGVAC), which recommended the expansion of the vaccination program. India began its vaccination drive in mid-January, starting with healthcare and frontline workers. Since then, over 13 million doses have been administered across the country. However, the pace of the vaccination drive has been slower than expected, with concerns raised over vaccine hesitancy and logistical challenges. The expansion of the vaccination drive to include the elderly and those with co-morbidities is a major step towards achieving herd immunity and controlling the spread of the virus in India. India has reported over 11 million cases of COVID-19, making it the second-worst affected country in the world after the United States. In summary, India's Health Ministry has announced that the country's COVID-19 vaccination drive will be expanded to include people over 60 and those over 45 with co-morbidities, covering an additional 270 million people. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(summary, text)\n",
        "print(\"ROUGE Score:\")\n",
        "print(\"Precision: {:.3f}\".format(scores[0]['rouge-1']['p']))\n",
        "print(\"Recall: {:.3f}\".format(scores[0]['rouge-1']['r']))\n",
        "print(\"F1-Score: {:.3f}\".format(scores[0]['rouge-1']['f']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f-X2zY727a2",
        "outputId": "ae4ff271-55b1-42a2-d0b3-03143bf906d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Score:\n",
            "Precision: 0.991\n",
            "Recall: 0.742\n",
            "F1-Score: 0.848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def summary_to_sentences(summary):\n",
        "    # Split the summary into sentences using the '.' character as a separator\n",
        "    sentences = summary.split('.')\n",
        "\n",
        "    # Convert each sentence into a list of words\n",
        "    sentence_lists = [sentence.split() for sentence in sentences]\n",
        "\n",
        "    return sentence_lists\n",
        "\n",
        "def paragraph_to_wordlist(paragraph):\n",
        "    # Split the paragraph into words using whitespace as a separator\n",
        "    words = paragraph.split()\n",
        "    return words\n",
        "\n",
        "reference_paragraph = text\n",
        "reference_summary = summary_to_sentences(reference_paragraph)\n",
        "predicted_paragraph = summary\n",
        "predicted_summary = paragraph_to_wordlist(predicted_paragraph)\n",
        "\n",
        "score = sentence_bleu(reference_summary, predicted_summary)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKyJhaLS2-Sp",
        "outputId": "3cf6e20a-21ae-4ee7-f664-4af2fde80c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7003175301310649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BLEU Score: {:.3f}\".format(score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij--6zx-3BzN",
        "outputId": "622424a5-f9ef-48e0-f142-fa3f537f450d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "def generate_summary_with_bart(text):\n",
        "    # Load pre-trained BART model and tokenizer\n",
        "    model_name = \"facebook/bart-large-cnn\"\n",
        "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(inputs.input_ids, num_beams=4, length_penalty=2.0, max_length=142, min_length=56, early_stopping=True)\n",
        "\n",
        "    # Decode the generated summary\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Example text\n",
        "input_text = \"\"\"\n",
        "The internet, a vast network of interconnected computers, has revolutionized communication, information dissemination, and numerous aspects of daily life. Its origins date back to the 1960s when the United States Department of Defense developed ARPANET (Advanced Research Projects Agency Network) as a means of secure communication. This early network laid the foundation for what would eventually become the modern internet.In the 1970s and 1980s, the development of key technologies such as TCP/IP (Transmission Control Protocol/Internet Protocol) facilitated the growth of interconnected networks. TCP/IP enabled different types of computer networks to communicate with each other, making it possible to create a global network of networks. This period also saw the rise of personal computers, which played a significant role in popularizing the internet among individual users. The launch of the World Wide Web (WWW) in 1991 by British scientist Tim Berners-Lee marked a major milestone in the evolution of the internet. The WWW allowed for the creation and sharing of information through web pages, making it accessible to a wider audience. Berners-Lee's invention of the first web browser, along with the introduction of HTML (HyperText Markup Language), provided the necessary tools for individuals and organizations to create and navigate websites.Throughout the 1990s, the internet experienced rapid growth. The advent of search engines like Yahoo! and Google transformed how users accessed information, making it easier to find relevant content. E-commerce also emerged during this period, with companies like Amazon and eBay pioneering online shopping and changing the retail landscape. Social networking sites, such as Friendster and MySpace, began to appear, laying the groundwork for the social media revolution.The 2000s saw the internet becoming an integral part of everyday life. The rise of high-speed broadband connections and wireless technology made internet access more widespread and convenient. Social media platforms like Facebook, Twitter, and Instagram connected people in unprecedented ways, allowing for instant communication and the sharing of personal experiences. Online video platforms like YouTube provided new avenues for content creation and consumption, giving rise to a new generation of digital influencers and content creators.The internet has also had a profound impact on various industries. In education, online learning platforms and digital resources have made education more accessible, enabling students to learn from anywhere in the world. In healthcare, telemedicine and health information systems have improved patient care and streamlined medical processes. The entertainment industry has been transformed by streaming services like Netflix and Spotify, which offer on-demand access to movies, TV shows, and music. The proliferation of mobile devices, such as smartphones and tablets, has further accelerated the internet's influence. Mobile apps have become a primary means of accessing information and services, from banking and shopping to social networking and entertainment. The integration of the internet into everyday objects, known as the Internet of Things (IoT), has led to the development of smart homes, connected cars, and wearable technology.Despite its many benefits, the internet has also presented challenges. Issues such as cybersecurity threats, privacy concerns, and the spread of misinformation have become increasingly prominent. Governments and organizations around the world are working to address these challenges through regulations, technological advancements, and public awareness campaigns.Looking ahead, the future of the internet holds exciting possibilities. The continued expansion of high-speed internet access and the development of new technologies, such as 5G networks and artificial intelligence, promise to further enhance connectivity and innovation. As the internet continues to evolve, it will undoubtedly shape the way we live, work, and interact in ways we have yet to imagine.\n",
        "\"\"\"\n",
        "\n",
        "# Generate summary using BART\n",
        "summary_bart = generate_summary_with_bart(input_text)\n",
        "print(\"Generated Summary (using BART):\")\n",
        "print(summary_bart)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68AVUcIzKzHB",
        "outputId": "2501dd87-9c09-434c-ba63-347b5ffd8290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary (using BART):\n",
            "The internet has revolutionized communication, information dissemination, and numerous aspects of daily life. Its origins date back to the 1960s when the United States Department of Defense developed ARPANET (Advanced Research Projects Agency Network) The launch of the World Wide Web in 1991 by British scientist Tim Berners-Lee marked a major milestone in the evolution of the internet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BART (Bidirectional and Auto-Regressive Transformers): BART is another transformer-based model developed by Facebook AI. It's particularly adept at text generation tasks like summarization due to its bidirectional architecture and autoregressive decoding. BART has been shown to perform well on various summarization benchmarks."
      ],
      "metadata": {
        "id": "yfKoK5RRnIPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "def generate_summary_with_bart(text):\n",
        "    # Load pre-trained BART model and tokenizer\n",
        "    model_name = \"facebook/bart-large-cnn\"\n",
        "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(inputs.input_ids, num_beams=4, length_penalty=2.0, max_length=142, min_length=56, early_stopping=True)\n",
        "\n",
        "    # Decode the generated summary\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Example text\n",
        "input_text = \"\"\"\n",
        "The internet, a vast network of interconnected computers, has revolutionized communication, information dissemination, and numerous aspects of daily life. Its origins date back to the 1960s when the United States Department of Defense developed ARPANET (Advanced Research Projects Agency Network) as a means of secure communication. This early network laid the foundation for what would eventually become the modern internet.In the 1970s and 1980s, the development of key technologies such as TCP/IP (Transmission Control Protocol/Internet Protocol) facilitated the growth of interconnected networks. TCP/IP enabled different types of computer networks to communicate with each other, making it possible to create a global network of networks. This period also saw the rise of personal computers, which played a significant role in popularizing the internet among individual users. The launch of the World Wide Web (WWW) in 1991 by British scientist Tim Berners-Lee marked a major milestone in the evolution of the internet. The WWW allowed for the creation and sharing of information through web pages, making it accessible to a wider audience. Berners-Lee's invention of the first web browser, along with the introduction of HTML (HyperText Markup Language), provided the necessary tools for individuals and organizations to create and navigate websites.Throughout the 1990s, the internet experienced rapid growth. The advent of search engines like Yahoo! and Google transformed how users accessed information, making it easier to find relevant content. E-commerce also emerged during this period, with companies like Amazon and eBay pioneering online shopping and changing the retail landscape. Social networking sites, such as Friendster and MySpace, began to appear, laying the groundwork for the social media revolution.The 2000s saw the internet becoming an integral part of everyday life. The rise of high-speed broadband connections and wireless technology made internet access more widespread and convenient. Social media platforms like Facebook, Twitter, and Instagram connected people in unprecedented ways, allowing for instant communication and the sharing of personal experiences. Online video platforms like YouTube provided new avenues for content creation and consumption, giving rise to a new generation of digital influencers and content creators.The internet has also had a profound impact on various industries. In education, online learning platforms and digital resources have made education more accessible, enabling students to learn from anywhere in the world. In healthcare, telemedicine and health information systems have improved patient care and streamlined medical processes. The entertainment industry has been transformed by streaming services like Netflix and Spotify, which offer on-demand access to movies, TV shows, and music. The proliferation of mobile devices, such as smartphones and tablets, has further accelerated the internet's influence. Mobile apps have become a primary means of accessing information and services, from banking and shopping to social networking and entertainment. The integration of the internet into everyday objects, known as the Internet of Things (IoT), has led to the development of smart homes, connected cars, and wearable technology.Despite its many benefits, the internet has also presented challenges. Issues such as cybersecurity threats, privacy concerns, and the spread of misinformation have become increasingly prominent. Governments and organizations around the world are working to address these challenges through regulations, technological advancements, and public awareness campaigns.Looking ahead, the future of the internet holds exciting possibilities. The continued expansion of high-speed internet access and the development of new technologies, such as 5G networks and artificial intelligence, promise to further enhance connectivity and innovation. As the internet continues to evolve, it will undoubtedly shape the way we live, work, and interact in ways we have yet to imagine.\n",
        "\"\"\"\n",
        "\n",
        "# Generate summary using BART\n",
        "summary_bart = generate_summary_with_bart(input_text)\n",
        "print(\"Generated Summary (using BART):\")\n",
        "print(summary_bart)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9cLe9GXnFPR",
        "outputId": "a78e60bb-45bb-40f8-cb47-055826711a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary (using BART):\n",
            "The internet has revolutionized communication, information dissemination, and numerous aspects of daily life. Its origins date back to the 1960s when the United States Department of Defense developed ARPANET (Advanced Research Projects Agency Network) The launch of the World Wide Web in 1991 by British scientist Tim Berners-Lee marked a major milestone in the evolution of the internet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"The Actual length of the summary_bart is : \", len(summary_bart))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj5f2zgdrWDo",
        "outputId": "73c20c9c-95fc-4fff-dc4c-b1c052a85307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Actual length of the summary_bart is :  388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text 1 Example"
      ],
      "metadata": {
        "id": "bo7Pa67ltDFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "from rouge import Rouge\n",
        "\n",
        "def generate_summary_with_bart(text):\n",
        "    # Load pre-trained BART model and tokenizer\n",
        "    model_name = \"facebook/bart-large-cnn\"\n",
        "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(inputs.input_ids, num_beams=4, length_penalty=2.0, max_length=142, min_length=56, early_stopping=True)\n",
        "\n",
        "    # Decode the generated summary\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Example text\n",
        "input_text = \"\"\"\n",
        "The internet, a vast network of interconnected computers, has revolutionized communication, information dissemination, and numerous aspects of daily life. Its origins date back to the 1960s when the United States Department of Defense developed ARPANET (Advanced Research Projects Agency Network) as a means of secure communication. This early network laid the foundation for what would eventually become the modern internet.In the 1970s and 1980s, the development of key technologies such as TCP/IP (Transmission Control Protocol/Internet Protocol) facilitated the growth of interconnected networks. TCP/IP enabled different types of computer networks to communicate with each other, making it possible to create a global network of networks. This period also saw the rise of personal computers, which played a significant role in popularizing the internet among individual users. The launch of the World Wide Web (WWW) in 1991 by British scientist Tim Berners-Lee marked a major milestone in the evolution of the internet. The WWW allowed for the creation and sharing of information through web pages, making it accessible to a wider audience. Berners-Lee's invention of the first web browser, along with the introduction of HTML (HyperText Markup Language), provided the necessary tools for individuals and organizations to create and navigate websites.Throughout the 1990s, the internet experienced rapid growth. The advent of search engines like Yahoo! and Google transformed how users accessed information, making it easier to find relevant content. E-commerce also emerged during this period, with companies like Amazon and eBay pioneering online shopping and changing the retail landscape. Social networking sites, such as Friendster and MySpace, began to appear, laying the groundwork for the social media revolution.The 2000s saw the internet becoming an integral part of everyday life. The rise of high-speed broadband connections and wireless technology made internet access more widespread and convenient. Social media platforms like Facebook, Twitter, and Instagram connected people in unprecedented ways, allowing for instant communication and the sharing of personal experiences. Online video platforms like YouTube provided new avenues for content creation and consumption, giving rise to a new generation of digital influencers and content creators.The internet has also had a profound impact on various industries. In education, online learning platforms and digital resources have made education more accessible, enabling students to learn from anywhere in the world. In healthcare, telemedicine and health information systems have improved patient care and streamlined medical processes. The entertainment industry has been transformed by streaming services like Netflix and Spotify, which offer on-demand access to movies, TV shows, and music. The proliferation of mobile devices, such as smartphones and tablets, has further accelerated the internet's influence. Mobile apps have become a primary means of accessing information and services, from banking and shopping to social networking and entertainment. The integration of the internet into everyday objects, known as the Internet of Things (IoT), has led to the development of smart homes, connected cars, and wearable technology.Despite its many benefits, the internet has also presented challenges. Issues such as cybersecurity threats, privacy concerns, and the spread of misinformation have become increasingly prominent. Governments and organizations around the world are working to address these challenges through regulations, technological advancements, and public awareness campaigns.Looking ahead, the future of the internet holds exciting possibilities. The continued expansion of high-speed internet access and the development of new technologies, such as 5G networks and artificial intelligence, promise to further enhance connectivity and innovation. As the internet continues to evolve, it will undoubtedly shape the way we live, work, and interact in ways we have yet to imagine.\n",
        "\"\"\"\n",
        "\n",
        "# Generate summary using BART\n",
        "summary_bart = generate_summary_with_bart(input_text)\n",
        "print(\"Generated Summary (using BART):\")\n",
        "print(summary_bart)\n",
        "\n",
        "# Evaluate the summary using ROUGE\n",
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(summary_bart, input_text, avg=True)\n",
        "print(\"ROUGE Score:\")\n",
        "print(\"Precision: {:.3f}\".format(scores['rouge-1']['p']))\n",
        "print(\"Recall: {:.3f}\".format(scores['rouge-1']['r']))\n",
        "print(\"F1-Score: {:.3f}\".format(scores['rouge-1']['f']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuZwuEp0sgtx",
        "outputId": "53c06356-ac1c-4daa-8e5c-951348df825e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary (using BART):\n",
            "The internet has revolutionized communication, information dissemination, and numerous aspects of daily life. Its origins date back to the 1960s when the United States Department of Defense developed ARPANET (Advanced Research Projects Agency Network) The launch of the World Wide Web in 1991 by British scientist Tim Berners-Lee marked a major milestone in the evolution of the internet.\n",
            "ROUGE Score:\n",
            "Precision: 1.000\n",
            "Recall: 0.140\n",
            "F1-Score: 0.245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text 2 Example"
      ],
      "metadata": {
        "id": "_5IpS5xjtQuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "from rouge import Rouge\n",
        "\n",
        "def generate_summary_with_bart(text):\n",
        "    # Load pre-trained BART model and tokenizer\n",
        "    model_name = \"facebook/bart-large-cnn\"\n",
        "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(inputs.input_ids, num_beams=4, length_penalty=2.0, max_length=142, min_length=56, early_stopping=True)\n",
        "\n",
        "    # Decode the generated summary\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Example text\n",
        "input_text = \"\"\"\n",
        "This is my first article on medium. Here, Iâ€™ll be giving a quick overview of what dimensionality reduction is, why we need it and how to do it. What is Dimensionality Reduction? Dimensionality reduction is simply, the process of reducing the dimension of your feature set. Your feature set could be a dataset with a hundred columns (i.e features) or it could be an array of points that make up a large sphere in the three-dimensional space. Dimensionality reduction is bringing the number of columns down to say, twenty or converting the sphere to a circle in the two-dimensional space. That is all well and good but why should we care? Why would we drop 80 columns off our dataset when we could straight up feed it to our machine learning algorithm and let it do the rest? The Curse of Dimensionality We care because the curse of dimensionality demands that we do. The curse of dimensionality refers to all the problems that arise when working with data in the higher dimensions, that did not exist in the lower dimensions. As the number of features increase, the number of samples also increases proportionally. The more features we have, the more number of samples we will need to have all combinations of feature values well represented in our sample. The Curse of Dimensionality As the number of features increases, the model becomes more complex. The more the number of features, the more the chances of overfitting. A machine learning model that is trained on a large number of features, gets increasingly dependent on the data it was trained on and in turn overfitted, resulting in poor performance on real data, beating the purpose. Avoiding overfitting is a major motivation for performing dimensionality reduction. The fewer features our training data has, the lesser assumptions our model makes and the simpler it will be. But that is not all and dimensionality reduction has a lot more advantages to offer, like Less misleading data means model accuracy improves. Less dimensions mean less computing. Less data means that algorithms train faster. Less data means less storage space required. Less dimensions allow usage of algorithms unfit for a large number of dimensions Removes redundant features and noise. Feature Selection and Feature Engineering for dimensionality reduction Dimensionality reduction could be done by both feature selection methods as well as feature engineering methods. Feature selection is the process of identifying and selecting relevant features for your sample. Feature engineering is manually generating new features from existing features, by applying some transformation or performing some operation on them. Feature selection can be done either manually or programmatically. For example, consider you are trying to build a model which predicts peopleâ€™s weights and you have collected a large corpus of data which describes each person quite thoroughly. If you had a column that described the color of each personâ€™s clothing, would that be much help in predicting their weight? I think we can safely agree it wonâ€™t be. This is something we can drop without further ado. What about a column that described their heights? Thatâ€™s a definite yes. We can make these simple manual feature selections and reduce the dimensionality when the relevance or irrelevance of certain features are obvious or common knowledge. And when its not glaringly obvious, there are a lot of tools we could employ to aid our feature selection. Heatmaps that show the correlation between features is a good idea. So is just visualising the relationship between the features and the target variable by plotting each feature against the target variable. Now let us look at a few programmatic methods for feature selection from the popular machine learning library sci-kit learn, namely, Variance Threshold and Univariate selection. Variance Threshold is a baseline approach to feature selection. As the name suggests, it drops all features where the variance along the column does not exceed a threshold value. The premise is that a feature which doesnâ€™t vary much within itself, has very little predictive power. >>> X = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]] >>> selector = VarianceThreshold() >>> selector.fit_transform(X) array([[2, 0], [1, 4], [1, 1]]) Univariate Feature Selection uses statistical tests to select features. Univariate describes a type of data which consists of observations on only a single characteristic or attribute. Univariate feature selection examines each feature individually to determine the strength of the relationship of the feature with the response variable. Some examples of statistical tests that can be used to evaluate feature relevance are Pearson Correlation, Maximal information coefficient, Distance correlation, ANOVA and Chi-square. Chi-square is used to find the relationship between categorical variables and Anova is preferred when the variables are continuous. Scikit-learn exposes feature selection routines likes SelectKBest, SelectPercentile or GenericUnivariateSelect as objects that implement a transform method based on the score of anova or chi2 or mutual information. Sklearn offers f_regression and mutual_info_regression as the scoring functions for regression and f_classif and mutual_info_classif for classification. F-Test checks for and only captures linear relationships between features and labels. A highly correlated feature is given higher score and less correlated features are given lower score. Correlation is highly deceptive as it doesnâ€™t capture strong non-linear relationships. On the other hand, mutual information methods can capture any kind of statistical dependency, but being nonparametric, they require more samples for accurate estimation. Feature selection is the simplest of dimensionality reduction methods. We will look at a few feature engineering methods for dimensionality reduction later. Linear Dimensionality Reduction Methods The most common and well known dimensionality reduction methods are the ones that apply linear transformations, like PCA (Principal Component Analysis) : Popularly used for dimensionality reduction in continuous data, PCA rotates and projects data along the direction of increasing variance. The features with the maximum variance are the principal components. Factor Analysis : a technique that is used to reduce a large number of variables into fewer numbers of factors. The values of observed data are expressed as functions of a number of possible causes in order to find which are the most important. The observations are assumed to be caused by a linear transformation of lower dimensional latent factors and added Gaussian noise. LDA (Linear Discriminant Analysis): projects data in a way that the class separability is maximised. Examples from same class are put closely together by the projection. Examples from different classes are placed far apart by the projection PCA orients data along the direction of the component with maximum variance whereas LDA projects the data to signify the class separability Non-linear Dimensionality Reduction Methods Non-linear transformation methods or manifold learning methods are used when the data doesnâ€™t lie on a linear subspace. It is based on the manifold hypothesis which says that in a high dimensional structure, most relevant information is concentrated in small number of low dimensional manifolds. If a linear subspace is a flat sheet of paper, then a rolled up sheet of paper is a simple example of a nonlinear manifold. Informally, this is called a Swiss roll, a canonical problem in the field of non-linear dimensionality reduction.\n",
        "\"\"\"\n",
        "\n",
        "# Generate summary using BART\n",
        "summary_bart = generate_summary_with_bart(input_text)\n",
        "print(\"Generated Summary (using BART):\")\n",
        "print(summary_bart)\n",
        "\n",
        "# Evaluate the summary using ROUGE\n",
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(summary_bart, input_text, avg=True)\n",
        "print(\"ROUGE Score:\")\n",
        "print(\"Precision: {:.3f}\".format(scores['rouge-1']['p']))\n",
        "print(\"Recall: {:.3f}\".format(scores['rouge-1']['r']))\n",
        "print(\"F1-Score: {:.3f}\".format(scores['rouge-1']['f']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-pqeafBs3gf",
        "outputId": "a3684a7f-5a75-4163-8668-19e0a3d7b0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary (using BART):\n",
            " Dimensionality reduction is the process of reducing the dimension of your feature set. As the number of features increases, the model becomes more complex. Less misleading data means model accuracy improves. Less data means that algorithms train faster. Less dimensions allow usage of algorithms unfit for a large number of dimensions. Removes redundant features and noise.\n",
            "ROUGE Score:\n",
            "Precision: 1.000\n",
            "Recall: 0.077\n",
            "F1-Score: 0.143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"The Actual length of the summary_bart is : \", len(summary_bart))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeWk0neYtn4R",
        "outputId": "4fb059b1-9d7e-4231-a985-756116910ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Actual length of the summary_bart is :  374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text 3 and 4 Example"
      ],
      "metadata": {
        "id": "RS8vRkoEtIQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "from rouge import Rouge\n",
        "\n",
        "def generate_summary_with_bart(text):\n",
        "    # Load pre-trained BART model and tokenizer\n",
        "    model_name = \"facebook/bart-large-cnn\"\n",
        "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(inputs.input_ids, num_beams=4, length_penalty=2.0, max_length=142, min_length=56, early_stopping=True)\n",
        "\n",
        "    # Decode the generated summary\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Example text\n",
        "input_text = \"\"\"\n",
        "Innocent Interpretations for Some Suspicious Statistics; General Election Data Exploration. (part 1) Looking at the 2019 elections in Israel. Some results appear weird, sure, but is there evidence of actual malfeasance, or is there a simpler explanation? Avishalom Shalit Â· Follow Published in Towards Data Science Â· 5 min read Â· Apr 22, 2019 -- Listen Share My favourite analogy in statistics(made by Cassie Kozyrkov) is the analogy to the English/American legal system. The â€œNull Hypothesisâ€ being the presumption of innocence (leading to acquittal) and the rejection of that can only be due to the presentation of evidence of guilt â€œbeyond a reasonable doubt.â€ the P value we select is that level of beyond a reasonable doubt. (which is different depending on the issue at stake) Our story begins with a post on social media. The following â€œanomalyâ€ in a specific polling station was making the rounds. All the parties got votes that were â€œVery Round Numbersâ€â„¢ These are indeed suspicious looking. OK, letâ€™s dive in. TL;DR and disclaimer In this multipart series, in some cases I will be able to present simple, innocent mathematical explanations for ostensibly suspicious results. In other cases I wonâ€™t. Note that there are more than 10,000 ballot boxes, so even a rare numerical anomaly is expected to crop up several times. Getting Started I started looking for other anomalies. Maybe round numbers are too obvious, but what are the odds that a party will get exactly a third of the votes? Half? Histogram Time True Data: Here is a histogram of the vote fraction of a specific party in all polling stations; Note the most common values are reduced small rationals: 1/2, 1/3, 3/7, 1/4, 2/5, 1/5, 4/9. weird, right? Foul play?!? Did we â€œget themâ€? Before I answer, can you think of an explanation of why exactly 1/2 is so popular? [Take a minute] [beat] Well, small rational fractions have a lot more going for them. You can get EXACTLY 1/3 by having 100 out of 300, 101 of 303, etc. but to get 200/601, well, you must have a very specific vote tally, and a very specific vote count for that party. So those values arenâ€™t as common. Is this enough to explain the oddity? Here are the results of a simple model (we pick random numbers for the total number of votes in the polling station, and number of votes for a specific party, given that partyâ€™s national total) The small rationals making an appearance again, even in a random model. (described in appendix B) Non damning histogram So, now that we have a simple explanation for these rational numbers in the data, what would be a good way to look at our data? How about if we let the histogram do what it wanted to from the start, which was to bin the data?If we take 100 bins, we can see if bin 50 is a lot more likely than bin 51 or 49 and thus judge. Binning makes the rational anomalies disappear. Well, it looks like we donâ€™t have enough evidence to convict. In the world where the Null hypothesis is true (no fudging) the evidence presented is actually quite reasonable and not at all surprising. That is not to say that there werenâ€™t instances of a single tally that was fudged and set to exactly 1/2 of the votes for a specific party, it is just not the conspiracy that it appeared to have been (with dozens of polling stations agreeing on the same ratio.) Next up This post will be first in a series. In the next weeks I will explore other anomalies. Iâ€™ll revisit the anomaly that started it all, and Iâ€™ll explore some weird rational relationships between parties. (i.e. one party getting 1/2 or twice that of another party) If youâ€™ve noticed some other weird lines youâ€™d like me to look at, comment and Iâ€™ll have a look. Get Ready Whet your appetite on this row of vote tallies (from one polling station). Note the recurring rational relationships. e.g. 25â€“25â€“75â€“150 ; 27â€“135 it also has the numbers 21,23,24,25,25,26,27. Suspicious, sure. Guilty? Is that weird enough to be suspect or just a coincidence? find out next week. Appendix A â€” code to load data. The results of the tallies per polling station are in here https://media21.bechirot.gov.il/files/expb.csv Here is some boilerplate python for loading that file (11K rows), and renaming the columns to English, So you can see for yourself, and find some more suspicious results. Also includes the code that generates the histograms above. Appendix B simplistic model Fitting a normal distribution to the number of valid votes per polling station (centred at 400 with sigma=100, ignoring the peak at 800) and a poisson distribution for the number of votes per party given the national party fractions, picking lambda from a distribution that matches the national vote fraction per ballot for that party. This is a bit simplistic I know, e.g. a PCA accounting for vote trends for different parties in different municipalities would be better. But this is good enough for now, it produces a viable reason for all those small rational numbers.\n",
        "\"\"\"\n",
        "\n",
        "# Generate summary using BART\n",
        "summary_bart = generate_summary_with_bart(input_text)\n",
        "print(\"Generated Summary (using BART):\")\n",
        "print(summary_bart)\n",
        "\n",
        "# Evaluate the summary using ROUGE\n",
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(summary_bart, input_text, avg=True)\n",
        "print(\"ROUGE Score:\")\n",
        "print(\"Precision: {:.3f}\".format(scores['rouge-1']['p']))\n",
        "print(\"Recall: {:.3f}\".format(scores['rouge-1']['r']))\n",
        "print(\"F1-Score: {:.3f}\".format(scores['rouge-1']['f']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY8boGYKt1Bp",
        "outputId": "4f649b1d-e0d5-4cde-f06e-b33a77ef6c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary (using BART):\n",
            "Innocent Interpretations for Some Suspicious Statistics; General Election Data Exploration. (part 1) Looking at the 2019 elections in Israel. Some results appear weird, sure, but is there evidence of actual malfeasance, or is there a simpler explanation? Avishalom Shalit Â· Follow Published in Towards Data Science.\n",
            "ROUGE Score:\n",
            "Precision: 1.000\n",
            "Recall: 0.092\n",
            "F1-Score: 0.168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"The Actual length of the summary_bart is : \", len(summary_bart))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvYABE5Zt-R-",
        "outputId": "684c6231-be64-4f27-dcf0-9b16bc57cff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Actual length of the summary_bart is :  316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text 5"
      ],
      "metadata": {
        "id": "PZzkAhxTvAJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "from rouge import Rouge\n",
        "\n",
        "def generate_summary_with_bart(text):\n",
        "    # Load pre-trained BART model and tokenizer\n",
        "    model_name = \"facebook/bart-large-cnn\"\n",
        "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(inputs.input_ids, num_beams=4, length_penalty=2.0, max_length=142, min_length=56, early_stopping=True)\n",
        "\n",
        "    # Decode the generated summary\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Example text\n",
        "input_text = \"\"\"\n",
        "10 Reads for Data Scientists Getting Started with Business Models If youâ€™re getting started with data science, youâ€™re probably focusing your attention on mostly stats and coding. Thereâ€™s nothing wrong with this, in fact, this is the right move â€” these are essential skills that you need to develop early on in your journey. With this being said, the biggest knowledge gap that Iâ€™ve encountered during my data science journey doesnâ€™t deal with either of these areas. Instead, upon starting my first full-time role as a data scientist, I realized, to my surprise, that I didnâ€™t really understand business. I suspect that this is a common theme. If you studied a technical field in college or picked things up using online courses, itâ€™s unlikely that you ever had any reason to deep dive into business concepts like models, strategy, or important metrics. Adding on to this, I didnâ€™t really come across data science interviews that stress-tested this type of understanding. Plenty of them tried to get a sense of product intuition, but I found that it rarely went beyond that. The fact is that business understanding isnâ€™t taught or evangelized in the data science community to the extent that itâ€™s used in practice. The goal of this post is to help bridge this gap by sharing some of the resources that I found most helpful as I got up to speed on how businesses work from the inside-out. This article from Andreessen Horowitz is a great place to start if youâ€™re trying to get familiar with the slew of metrics and acronyms that get thrown around in a business, whether itâ€™s a startup or not. On a more general note, their posts are consistently high-quality and are almost always worth your time. If you have a larger appetite, check out their follow-up post on 16 more metrics and the thread below for some additional tips on metrics. Some helpful tips on misleading metrics An overall solid resource, the articles at FourWeekMBA are worth exploring at some point. I particularly recommend this for an overview of all the different business models out there. Itâ€™s hard to come away from this without learning something new. For a more practical dive into business models, I also found this post going over how Slack makes money interesting. This one is a bit denser than the previous two, but itâ€™s really excellent. The unmissable Ben Thompson from Stratechery goes over how markets work and why certain companies are dominating their industry. The takeaway from this post is that markets have three components, and the companies that can monopolize two of the three typically win out in a big way. Think Netflix. A lot of what weâ€™ve seen so far has been conceptual, so letâ€™s look at a specific model and analyze why it does and doesnâ€™t work. Another one of my favorite business writers out there, Andrew Chen looks at the dating industry and why most investors donâ€™t find it attractive. Other great essays from the venture capitalist commonly cover things like growth and metrics. More from Ben Thompson, hereâ€™s another great essay from him. This time on how large companies, particularly Facebook and Google, process data from its raw form to something uniquely valuable. Published in Fall 2018, this provides a good early look into the business side of all of the data privacy and regulation concerns weâ€™re seeing now. If youâ€™re not familiar with LTV (lifetime value), then youâ€™ll probably have to get familiar with it at some point. Thereâ€™s plenty of resources out there regarding the metric, but this is probably my favorite go-to on the subject. It clearly explains how to calculate LTV, and why you should think twice before you blindly buy into it without context. This short post focuses on the SaaS (software as a service) business model. The basic idea is outlined quite simply in the picture below, but Iâ€™d still recommend you take the time to read the full write-up. Christoph Janz really does an excellent job of taking a complex question and breaking it down. He also recently updated the chart in a new post. Co-founder and former CEO of StackOverflow, Joel Spolsky hammers home a crucial part-business, part-economics lesson here: Smart companies try to commoditize their productsâ€™ complements. Whether they succeed or not is a very different story, shown here with plenty of examples. We covered a few ways that companies can make money, but this resource takes the most simplistic (and still accurate) approach. It all started with Jim Barksdale at a trade show. As he was heading out the door to catch a flight, he left the audience with one last pearl of wisdom before departing, one that sums up the post quite nicely. â€œGentlemen, thereâ€™s only two ways I know of to make money: bundling and unbundling.â€ Last but not least, if you want to take things a step further, I recommend case studies. You can find a ton of them out there from top universities like Stanford and Harvard for cheap or often no cost at all. Once you have a grasp on the fundamentals, this an excellent way to continue to supplement your learning. This is where Iâ€™m currently at â€” Iâ€™ve challenged myself to take on one case study every two weeks over the summer. Join me on the ride! Wrapping Up That does it for the list. I know all of the above links really helped me out and I hope you take the time to explore them. As you might have noticed, not all of them tie into the day-to-day life of a data scientist â€” thatâ€™s intentional. I said this in my last post, Iâ€™ll say it again â€” data scientists are thinkers. We do our best work when we understand the systems that surround us. This understanding is what sets us up for the cool stuff: exploratory analysis, machine learning, and data visualization. Lay the foundation first and reap the benefits later. Thatâ€™s what itâ€™s all about. The resources selected above were heavily influenced by SVP of Strategy at Squarespace, Andrew Bartholomewâ€™s reading list.\n",
        "\"\"\"\n",
        "\n",
        "# Generate summary using BART\n",
        "summary_bart = generate_summary_with_bart(input_text)\n",
        "print(\"Generated Summary (using BART):\")\n",
        "print(summary_bart)\n",
        "\n",
        "# Evaluate the summary using ROUGE\n",
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(summary_bart, input_text, avg=True)\n",
        "print(\"ROUGE Score:\")\n",
        "print(\"Precision: {:.3f}\".format(scores['rouge-1']['p']))\n",
        "print(\"Recall: {:.3f}\".format(scores['rouge-1']['r']))\n",
        "print(\"F1-Score: {:.3f}\".format(scores['rouge-1']['f']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PCPFYsWu6Wh",
        "outputId": "a4be28de-7c77-4a9f-e3f7-0484e83811ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary (using BART):\n",
            "10 Reads for Data Scientists Getting Started with Business Models. The goal of this post is to help bridge this gap by sharing some of the resources that I found most helpful as I got up to speed on how businesses work from the inside-out. We covered a few ways that companies can make money, but this resource takes the most simplistic approach.\n",
            "ROUGE Score:\n",
            "Precision: 1.000\n",
            "Recall: 0.102\n",
            "F1-Score: 0.184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"The Actual length of the summary_bart is : \", len(summary_bart))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cPU7YluvJAf",
        "outputId": "2dd9a0ce-d03e-42c5-9ffc-7966d59ddde1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Actual length of the summary_bart is :  346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_name = 't5-small'\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Example text\n",
        "text = \"The internet, a vast network of interconnected computers, has revolutionized communication, information dissemination, and numerous aspects of daily life. Its origins date back to the 1960s when the United States Department of Defense developed ARPANET (Advanced Research Projects Agency Network) as a means of secure communication. This early network laid the foundation for what would eventually become the modern internet.In the 1970s and 1980s, the development of key technologies such as TCP/IP (Transmission Control Protocol/Internet Protocol) facilitated the growth of interconnected networks. TCP/IP enabled different types of computer networks to communicate with each other, making it possible to create a global network of networks. This period also saw the rise of personal computers, which played a significant role in popularizing the internet among individual users. The launch of the World Wide Web (WWW) in 1991 by British scientist Tim Berners-Lee marked a major milestone in the evolution of the internet. The WWW allowed for the creation and sharing of information through web pages, making it accessible to a wider audience. Berners-Lee's invention of the first web browser, along with the introduction of HTML (HyperText Markup Language), provided the necessary tools for individuals and organizations to create and navigate websites.Throughout the 1990s, the internet experienced rapid growth. The advent of search engines like Yahoo! and Google transformed how users accessed information, making it easier to find relevant content. E-commerce also emerged during this period, with companies like Amazon and eBay pioneering online shopping and changing the retail landscape. Social networking sites, such as Friendster and MySpace, began to appear, laying the groundwork for the social media revolution.The 2000s saw the internet becoming an integral part of everyday life. The rise of high-speed broadband connections and wireless technology made internet access more widespread and convenient. Social media platforms like Facebook, Twitter, and Instagram connected people in unprecedented ways, allowing for instant communication and the sharing of personal experiences. Online video platforms like YouTube provided new avenues for content creation and consumption, giving rise to a new generation of digital influencers and content creators.The internet has also had a profound impact on various industries. In education, online learning platforms and digital resources have made education more accessible, enabling students to learn from anywhere in the world. In healthcare, telemedicine and health information systems have improved patient care and streamlined medical processes. The entertainment industry has been transformed by streaming services like Netflix and Spotify, which offer on-demand access to movies, TV shows, and music. The proliferation of mobile devices, such as smartphones and tablets, has further accelerated the internet's influence. Mobile apps have become a primary means of accessing information and services, from banking and shopping to social networking and entertainment. The integration of the internet into everyday objects, known as the Internet of Things (IoT), has led to the development of smart homes, connected cars, and wearable technology.Despite its many benefits, the internet has also presented challenges. Issues such as cybersecurity threats, privacy concerns, and the spread of misinformation have become increasingly prominent. Governments and organizations around the world are working to address these challenges through regulations, technological advancements, and public awareness campaigns.Looking ahead, the future of the internet holds exciting possibilities. The continued expansion of high-speed internet access and the development of new technologies, such as 5G networks and artificial intelligence, promise to further enhance connectivity and innovation. As the internet continues to evolve, it will undoubtedly shape the way we live, work, and interact in ways we have yet to imagine.\"\n",
        "\n",
        "# Measure time for data preprocessing\n",
        "start_time = time.time()\n",
        "inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "end_time = time.time()\n",
        "preprocessing_time = end_time - start_time\n",
        "print(f\"Time taken for data preprocessing: {preprocessing_time:.4f} seconds\")\n",
        "\n",
        "# Measure time for model inference\n",
        "start_time = time.time()\n",
        "summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "end_time = time.time()\n",
        "inference_time = end_time - start_time\n",
        "print(f\"Time taken for model inference: {inference_time:.4f} seconds\")\n",
        "\n",
        "# Decode the summary\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(\"Summary:\", summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJAEgJK8DAOI",
        "outputId": "7341d23d-0451-4f2d-9a71-7826900933c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for data preprocessing: 0.0166 seconds\n",
            "Time taken for model inference: 12.9731 seconds\n",
            "Summary: the internet, a vast network of interconnected computers, has revolutionized communication, information dissemination, and numerous aspects of daily life. it was developed in the 1960s when the united states department of defense developed ARPANET (Advanced Research Projects Agency Network) as a means of secure communication. in the 1970s and 1980s, the development of key technologies such as TCP/IP facilitated the growth of interconnected networks.\n"
          ]
        }
      ]
    }
  ]
}